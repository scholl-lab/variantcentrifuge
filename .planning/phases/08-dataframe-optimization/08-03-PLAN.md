---
phase: 08-dataframe-optimization
plan: 03
type: execute
wave: 2
depends_on: ["08-01"]
files_modified:
  - variantcentrifuge/stages/output_stages.py
  - variantcentrifuge/converter.py
autonomous: true

must_haves:
  truths:
    - "ExcelReportStage uses context.variants_df when available instead of re-reading TSV from disk"
    - "convert_to_excel accepts optional DataFrame argument to skip disk read"
    - "Column names restored to original (pre-sanitization) names before writing output files"
    - "TSV output still written to disk as standard artifact (users depend on it)"
    - "Fallback to disk read works when variants_df is None"
  artifacts:
    - path: "variantcentrifuge/stages/output_stages.py"
      provides: "ExcelReportStage with DataFrame pass-through from context"
      contains: "variants_df"
    - path: "variantcentrifuge/converter.py"
      provides: "convert_to_excel with optional df parameter"
      contains: "def convert_to_excel"
  key_links:
    - from: "variantcentrifuge/stages/output_stages.py"
      to: "variantcentrifuge/pipeline_core/context.py"
      via: "context.variants_df and context.column_rename_map"
      pattern: "context\\.variants_df"
    - from: "variantcentrifuge/stages/output_stages.py"
      to: "variantcentrifuge/converter.py"
      via: "convert_to_excel(df=df) parameter"
      pattern: "convert_to_excel"
---

<objective>
Eliminate redundant TSV-to-DataFrame disk read in ExcelReportStage by using the in-memory DataFrame from PipelineContext, and restore original column names for output.

Purpose: The ExcelReportStage currently reads the final TSV back from disk via `convert_to_excel(str(input_file))`, which re-parses the entire file. Since the DataFrame already exists in `context.variants_df` (set by Plan 01), we can pass it directly, eliminating one full disk read cycle. Column names must be restored to their original (pre-sanitization) names before writing any output to preserve backwards compatibility.

Output: ExcelReportStage uses in-memory DataFrame when available, with disk fallback. TSVOutputStage restores column names before writing. converter.py accepts DataFrame directly.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/08-dataframe-optimization/08-CONTEXT.md
@.planning/phases/08-dataframe-optimization/08-01-SUMMARY.md
@variantcentrifuge/stages/output_stages.py
@variantcentrifuge/converter.py
@variantcentrifuge/pipeline_core/context.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add column name restoration to TSVOutputStage and DataFrame pass-through to ExcelReportStage</name>
  <files>
    variantcentrifuge/stages/output_stages.py
    variantcentrifuge/converter.py
  </files>
  <action>
**In `variantcentrifuge/stages/output_stages.py` TSVOutputStage._process (around line 447):**

Before writing TSV output (line 536 `df.to_csv(...)`), restore original column names:
```python
# Restore original column names before writing output
if context.column_rename_map:
    reverse_map = {v: k for k, v in context.column_rename_map.items()}
    df = df.rename(columns=reverse_map)
    logger.debug(f"Restored {len(reverse_map)} column names for output")
```

This ensures the TSV output has the original column names (e.g., `GEN[0].GT` not `GEN_0__GT`) for backwards compatibility.

**In `variantcentrifuge/converter.py` convert_to_excel function (line ~43):**

Add optional `df` parameter:
```python
def convert_to_excel(tsv_file: str, cfg: dict | None = None, df: pd.DataFrame | None = None) -> str:
```

If `df` is provided, skip the `pd.read_csv(tsv_file, ...)` call and use the provided DataFrame directly. The rest of the function (column dropping, Excel writing) stays the same. Still derive `xlsx_file` from `tsv_file` path.

**In `variantcentrifuge/stages/output_stages.py` ExcelReportStage._process (around line 575):**

Before calling `convert_to_excel`, check for in-memory DataFrame:
```python
# Use in-memory DataFrame if available (avoids redundant disk read)
excel_df = None
if context.variants_df is not None:
    excel_df = context.variants_df.copy()  # Copy to avoid mutation
    # Restore original column names for Excel output
    if context.column_rename_map:
        reverse_map = {v: k for k, v in context.column_rename_map.items()}
        excel_df = excel_df.rename(columns=reverse_map)
    logger.info("Using in-memory DataFrame for Excel generation (skipping disk read)")

xlsx_file = convert_to_excel(str(input_file), context.config, df=excel_df)
```

**IMPORTANT:** The TSV file MUST still be written to disk first (TSVOutputStage runs before ExcelReportStage). The TSV is a standard output artifact that users depend on. The optimization only skips the RE-READ of that file for Excel generation.

Do NOT modify HTMLReportStage or IGVReportStage - those use different generation paths and are out of scope for this plan.
  </action>
  <verify>
    `cd /mnt/c/development/scholl-lab/variantcentrifuge && python -m pytest tests/unit/ -v -x --timeout=60`
    `cd /mnt/c/development/scholl-lab/variantcentrifuge && python -m pytest tests/integration/ -v -x --timeout=120 -k "not slow"`
    `cd /mnt/c/development/scholl-lab/variantcentrifuge && python -c "from variantcentrifuge.converter import convert_to_excel; import inspect; sig = inspect.signature(convert_to_excel); print('df' in sig.parameters)"`
  </verify>
  <done>
    ExcelReportStage uses context.variants_df when available (skips disk re-read). convert_to_excel accepts optional df parameter. TSVOutputStage restores original column names before writing. All tests pass unchanged.
  </done>
</task>

</tasks>

<verification>
- `grep -n "variants_df" variantcentrifuge/stages/output_stages.py` shows ExcelReportStage using context.variants_df
- `grep -n "column_rename_map" variantcentrifuge/stages/output_stages.py` shows column name restoration in TSVOutputStage and ExcelReportStage
- `python -c "from variantcentrifuge.converter import convert_to_excel; import inspect; sig = inspect.signature(convert_to_excel); print('df' in sig.parameters)"` prints True
- `python -m pytest tests/ -v -x --timeout=180 -k "not slow and not performance"` all pass
</verification>

<success_criteria>
- ExcelReportStage reads from context.variants_df when available (one fewer disk read)
- Fallback to disk read works when variants_df is None
- convert_to_excel accepts optional DataFrame parameter
- TSV output has original column names (backwards compatible)
- Excel output has original column names (backwards compatible)
- All existing tests pass unchanged
</success_criteria>

<output>
After completion, create `.planning/phases/08-dataframe-optimization/08-03-SUMMARY.md`
</output>
