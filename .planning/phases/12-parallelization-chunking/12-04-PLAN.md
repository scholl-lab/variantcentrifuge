---
phase: 12-parallelization-chunking
plan: 04
type: execute
wave: 3
depends_on: ["12-02", "12-03"]
files_modified:
  - tests/performance/benchmark_parallelism.py
autonomous: true

must_haves:
  truths:
    - "Benchmark tests measure parallel vs sequential inheritance analysis at 100, 1K, 10K variant scales"
    - "Gene sorting improvement is measurable via benchmark (largest-first vs unsorted submission)"
    - "Auto-worker detection produces reasonable values on test machine"
    - "All existing tests pass with zero regressions"
    - "No dead code remains: InheritanceMemoryManager gone, dead CLI flags gone"
  artifacts:
    - path: "tests/performance/benchmark_parallelism.py"
      provides: "Parallelism benchmarks for Phase 12 verification"
      min_lines: 60
  key_links:
    - from: "tests/performance/benchmark_parallelism.py"
      to: "variantcentrifuge/inheritance/parallel_analyzer.py"
      via: "benchmark import"
      pattern: "from variantcentrifuge.inheritance.parallel_analyzer import"
---

<objective>
Create parallelism benchmarks and run full verification to confirm Phase 12 improvements work correctly with no regressions.

Purpose: Phase 12 CONTEXT requires benchmarks proving improved scaling. This plan creates the benchmark infrastructure and runs comprehensive verification.

Output: Benchmark tests, full test suite green, verification of all Phase 12 changes.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/12-parallelization-chunking/12-CONTEXT.md
@.planning/phases/12-parallelization-chunking/12-01-SUMMARY.md
@.planning/phases/12-parallelization-chunking/12-02-SUMMARY.md
@.planning/phases/12-parallelization-chunking/12-03-SUMMARY.md
@tests/performance/benchmark_inheritance.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create parallelism benchmarks</name>
  <files>
    tests/performance/benchmark_parallelism.py
  </files>
  <action>
Create `tests/performance/benchmark_parallelism.py` following patterns from existing `tests/performance/benchmark_inheritance.py`.

**Benchmark tests:**

1. `test_benchmark_parallel_vs_sequential_1k` (marked `@pytest.mark.slow`):
   - Generate 1K variant synthetic DataFrame with 10 samples using existing synthetic data generators
   - Run `analyze_inheritance_parallel()` with `n_workers=1` (sequential baseline)
   - Run `analyze_inheritance_parallel()` with `n_workers=None` (auto-detect)
   - Use pytest-benchmark to measure both
   - Assert: parallel is not slower than sequential for 1K variants (ratio >= 0.8)

2. `test_benchmark_parallel_vs_sequential_10k` (marked `@pytest.mark.slow`):
   - Generate 10K variant synthetic DataFrame with 10 samples
   - Same comparison as above
   - Assert: parallel achieves >= 1.0x speedup at 10K scale (benefit visible at scale)

3. `test_benchmark_gene_sorting_effect` (marked `@pytest.mark.slow`):
   - Generate 10K variants distributed across genes with skewed sizes (1 gene with 5000 variants, rest small)
   - Measure time with gene sorting (current implementation) vs without sorting (shuffle genes before submission)
   - Assert: sorted submission is >= 0.9x of unsorted (at minimum not worse; may be better with real parallelism)

4. `test_auto_worker_detection`:
   - NOT slow — just verifies ResourceManager returns reasonable values
   - Create ResourceManager, call `auto_workers(task_count=100, memory_per_task_gb=0.1)`
   - Assert: returns between 1 and os.cpu_count()
   - Assert: returns >= 1

5. `test_resource_manager_chunk_size`:
   - NOT slow — verifies auto chunk size
   - Create ResourceManager
   - Test with 100 variants / 10 samples -> chunk >= 100 (fits in memory)
   - Test with 1M variants / 5000 samples -> chunk < 1M (needs splitting)

Use existing synthetic data generator from `tests/performance/conftest.py` or `tests/fixtures/` for DataFrame creation. Follow existing benchmark patterns (pytest-benchmark fixtures, group names, metadata).
  </action>
  <verify>
    `pytest tests/performance/benchmark_parallelism.py -v -k "not slow"` passes (non-slow tests).
    `pytest tests/performance/benchmark_parallelism.py -v -m slow --timeout=120` passes (slow benchmarks, may take 1-2 min).
  </verify>
  <done>
    5 benchmark tests created. Auto-detection tests pass quickly. Slow benchmarks measure parallel vs sequential at scale.
  </done>
</task>

<task type="auto">
  <name>Task 2: Full verification sweep</name>
  <files>
    (no new files — verification only)
  </files>
  <action>
Run comprehensive verification to confirm all Phase 12 changes work correctly:

1. **Dead code verification:**
   - `grep -r "InheritanceMemoryManager" variantcentrifuge/ tests/` → ZERO results
   - `grep -r "inheritance_memory_manager" variantcentrifuge/ tests/` → ZERO results (only .planning/)
   - `grep -r "\-\-chunks" variantcentrifuge/cli.py` → ZERO results
   - `grep -r "vectorized.chunk.size" variantcentrifuge/cli.py` → ZERO results
   - `grep -r "genotype.replacement.chunk.size" variantcentrifuge/cli.py` → ZERO results

2. **Full test suite:**
   - `make ci-check` passes
   - `pytest -m unit --tb=short` → all unit tests pass
   - `pytest tests/test_inheritance/ -v` → all inheritance tests pass
   - `pytest tests/unit/memory/ -v` → ResourceManager tests pass
   - `pytest tests/unit/pipeline_core/ -v` → runner tests pass (including memory reporting)

3. **Import verification:**
   - `python -c "from variantcentrifuge.memory import ResourceManager; print('OK')"` → OK
   - `python -c "from variantcentrifuge.memory import InheritanceMemoryManager"` → ImportError (deleted)
   - `python -c "from variantcentrifuge.cli import create_parser; p = create_parser(); p.parse_args([])"` → no error

4. **Golden file validation:**
   - `pytest tests/unit/inheritance/test_golden_files.py -v` → all 14 golden file tests pass (inheritance output unchanged)

If ANY verification fails, fix the issue before completing this task. Document any fixes made.
  </action>
  <verify>
    ALL checks in the action list pass. `make ci-check` is the final gate.
  </verify>
  <done>
    Zero dead code. All tests pass (unit, inheritance, golden files, benchmarks). CI green. Phase 12 verified.
  </done>
</task>

</tasks>

<verification>
1. `make ci-check` — full CI passes
2. `pytest tests/performance/benchmark_parallelism.py -v -k "not slow"` — quick benchmarks pass
3. Dead code grep returns zero results for InheritanceMemoryManager and removed CLI flags
4. Golden file tests prove inheritance output unchanged
</verification>

<success_criteria>
- 5 benchmark tests exist and pass
- Full test suite green (make ci-check)
- Zero dead code (InheritanceMemoryManager, dead CLI flags)
- Golden files prove no regression in inheritance output
- ResourceManager auto-detection produces reasonable values
</success_criteria>

<output>
After completion, create `.planning/phases/12-parallelization-chunking/12-04-SUMMARY.md`
</output>
