---
phase: 06-benchmark-framework
plan: 03
type: execute
wave: 2
depends_on: ["06-01"]
files_modified:
  - tests/performance/benchmark_ratio_assertions.py
  - tests/performance/benchmark_memory_budgets.py
autonomous: true

must_haves:
  truths:
    - "Ratio assertions compare vectorized vs sequential within the same test run"
    - "Speedup ratio is computed as sequential_time / vectorized_time and asserted > 1.0"
    - "Ratio assertions have zero CI flakiness because both implementations run on the same machine in the same test"
    - "Memory budget tests use tracemalloc to measure peak memory per component"
    - "Memory budget violations produce warnings, never hard test failures"
    - "Memory tests are separate from timing tests (tracemalloc overhead does not skew timing)"
  artifacts:
    - path: "tests/performance/benchmark_ratio_assertions.py"
      provides: "Ratio assertions for vectorized vs sequential implementations"
      contains: "speedup"
      min_lines: 60
    - path: "tests/performance/benchmark_memory_budgets.py"
      provides: "Memory budget enforcement tests via tracemalloc"
      contains: "tracemalloc"
      min_lines: 60
  key_links:
    - from: "tests/performance/benchmark_ratio_assertions.py"
      to: "variantcentrifuge/inheritance/comp_het.py"
      via: "import"
      pattern: "analyze_gene_for_compound_het"
    - from: "tests/performance/benchmark_ratio_assertions.py"
      to: "variantcentrifuge/inheritance/comp_het_vectorized.py"
      via: "import"
      pattern: "analyze_gene_for_compound_het_vectorized"
    - from: "tests/performance/benchmark_memory_budgets.py"
      to: "tests/performance/helpers/memory_budgets.py"
      via: "import"
      pattern: "from .helpers.memory_budgets import"
---

<objective>
Create ratio assertion tests that compare vectorized vs sequential implementations within the same run (zero flakiness), and memory budget enforcement tests using tracemalloc with warning-only violations.

Purpose: Ratio assertions (BENCH-04) enable reliable implementation comparison without cross-run variance. Memory budgets (BENCH-05) catch memory regressions early. These are structurally different from the component benchmarks in Plan 02 — ratio tests time both implementations and compute a ratio, memory tests use tracemalloc (which must NOT run during timing benchmarks due to 5-20% overhead).
Output: Two test files covering ratio assertions and memory budget enforcement.
</objective>

<execution_context>
@C:\Users\bernt\.claude/get-shit-done/workflows/execute-plan.md
@C:\Users\bernt\.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/phases/06-benchmark-framework/06-RESEARCH.md
@.planning/phases/06-benchmark-framework/06-CONTEXT.md
@.planning/phases/06-benchmark-framework/06-01-SUMMARY.md

# Source code with dual implementations:
@variantcentrifuge/inheritance/comp_het.py
@variantcentrifuge/inheritance/comp_het_vectorized.py
@variantcentrifuge/inheritance/analyzer.py

# Fixtures:
@tests/performance/conftest.py
@tests/performance/helpers/synthetic_data.py
@tests/performance/helpers/memory_budgets.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create ratio assertion tests for vectorized vs sequential comparisons</name>
  <files>
    tests/performance/benchmark_ratio_assertions.py
  </files>
  <action>
    Create ratio assertion tests that time both implementations in the same test and compute speedup. These tests do NOT use the pytest-benchmark fixture for timing — they use time.perf_counter directly so both implementations are measured under identical conditions in the same process.

    1. `test_comp_het_vectorized_vs_original_ratio(synthetic_variants)`:
       - Generate data: n_variants=1000, n_samples=3 (trio), seed=42
       - Generate trio pedigree
       - Filter to a single gene with multiple variants (at least 5+ variants in one gene)
       - Time `analyze_gene_for_compound_het(gene_df, pedigree, sample_list)` — run 5 iterations, compute mean
       - Time `analyze_gene_for_compound_het_vectorized(gene_df, pedigree, sample_list)` — run 5 iterations, compute mean
       - Compute speedup = sequential_mean / vectorized_mean
       - `assert speedup > 1.0, f"Vectorized comp_het should be faster, got {speedup:.2f}x"`
       - Print speedup for console visibility

    2. `test_comp_het_ratio_at_scale(synthetic_variants, n_variants)`:
       - Parametrize n_variants: [500, 2000]
       - Same structure as above but parametrized to show how ratio changes with scale
       - Speedup assertion: `assert speedup > 1.0`

    NOTE: The comp_het functions are the ONLY pair with a clear vectorized vs original implementation in the current codebase. The genotype replacement pair (replacer.py vs vectorized_replacer.py) has different function signatures (iterator of lines vs file-based), making direct ratio comparison more complex. Focus ratio assertions on comp_het where the comparison is cleanest.

    If the vectorized comp_het is NOT actually faster than the original at small scales (possible for n_variants < 100 due to NumPy overhead), that's a valid benchmark finding. For the assertion, use n_variants >= 500 where vectorization should win. If it doesn't, the assertion will correctly identify that the "vectorized" implementation isn't providing the expected benefit — which is useful information for Phase 9.

    IMPORTANT: These tests do NOT use the `benchmark` fixture. They use `time.perf_counter()` directly. This is intentional — ratio assertions need both implementations timed in the same function. The `benchmark` fixture can only time one function per test.

    Mark all tests with `@pytest.mark.performance`.
  </action>
  <verify>
    - `pytest tests/performance/benchmark_ratio_assertions.py --benchmark-disable -v` — all tests pass
    - The test output shows speedup ratios printed to console
    - Verify that `assert speedup > 1.0` is present in the test code (not just > 0 or some trivial assertion)
  </verify>
  <done>
    Ratio assertions compare vectorized vs sequential compound het within the same run, computing and asserting speedup > 1.0. Tests are zero-flakiness because they compare within the same process under identical conditions (BENCH-04).
  </done>
</task>

<task type="auto">
  <name>Task 2: Create memory budget enforcement tests with tracemalloc</name>
  <files>
    tests/performance/benchmark_memory_budgets.py
  </files>
  <action>
    Create memory profiling tests that measure peak memory for each component using the MemoryTracker helper from Plan 01. These tests are SEPARATE from timing benchmarks because tracemalloc adds 5-20% overhead that would skew timing measurements.

    1. `test_inheritance_memory_budget(synthetic_variants)`:
       - Generate data: n_variants=10000, n_samples=3 (trio)
       - Generate trio pedigree
       - Use MemoryTracker context manager to wrap `analyze_inheritance(df, pedigree, sample_list)`
       - Record peak_mb in test output
       - Call `warn_if_over_budget(peak_mb, INHERITANCE_BUDGET_MB, "inheritance analysis 10K variants")`
       - Assert result is not None (correctness check only — memory is warning-only)

    2. `test_comp_het_memory_budget(synthetic_variants)`:
       - Generate data: n_variants=5000, n_samples=3 (one gene worth of variants for stress test)
       - Filter to single gene
       - Use MemoryTracker to wrap `analyze_gene_for_compound_het_vectorized(gene_df, pedigree, sample_list)`
       - Warn if over COMP_HET_BUDGET_MB
       - Record peak_mb

    3. `test_gene_burden_memory_budget(synthetic_gene_burden_data)`:
       - Generate data: n_variants=10000, n_samples=100, n_genes=50
       - Use MemoryTracker to wrap `perform_gene_burden_analysis(df, cfg)`
       - Warn if over GENE_BURDEN_BUDGET_MB
       - Record peak_mb

    4. `test_scoring_memory_budget(synthetic_variants, synthetic_scoring_config)`:
       - Generate data: n_variants=10000, n_samples=10
       - Use MemoryTracker to wrap `apply_scoring(df, scoring_config)`
       - Warn if over SCORING_BUDGET_MB
       - Record peak_mb

    5. `test_dataframe_read_memory_budget(synthetic_variants, tmp_path)`:
       - Write 50000-variant DataFrame to TSV
       - Use MemoryTracker to wrap `pd.read_csv(path, sep='\t')`
       - Record peak_mb, print to console
       - This establishes baseline memory for DataFrame loading at scale

    For ALL memory tests:
    - Mark with `@pytest.mark.performance`
    - Do NOT use the pytest-benchmark fixture (no `benchmark` parameter). These are plain pytest tests.
    - Print peak_mb to console for visibility: `print(f"Peak memory: {peak_mb:.1f} MB")`
    - Memory violations are warnings ONLY — never assert on memory (per CONTEXT.md decision)
    - The only assertions are on correctness (result is not None, result has expected shape, etc.)

    IMPORTANT: tracemalloc.start() and tracemalloc.stop() must be balanced. Use the MemoryTracker context manager which handles this. Do not nest multiple MemoryTracker contexts — tracemalloc is a global state and nesting causes incorrect measurements.
  </action>
  <verify>
    - `pytest tests/performance/benchmark_memory_budgets.py -v -s` — all tests pass, peak memory values printed to console
    - No test FAILS due to memory budget violation (verify warnings are issued but tests pass)
    - grep for `assert.*peak_mb` or `assert.*memory` — should find zero matches (memory is warning-only)
    - grep for `warn_if_over_budget` — should find matches in each test function
  </verify>
  <done>
    Memory budget tests measure peak memory via tracemalloc for inheritance, comp_het, gene burden, scoring, and DataFrame I/O. Budget violations produce warnings only, never test failures. Tests are separate from timing benchmarks to avoid tracemalloc overhead contamination (BENCH-05).
  </done>
</task>

</tasks>

<verification>
- `pytest tests/performance/benchmark_ratio_assertions.py tests/performance/benchmark_memory_budgets.py -v -s` — all tests pass
- Ratio tests print speedup values to console
- Memory tests print peak_mb values to console
- No hard failures from memory budget violations
- No use of `benchmark` fixture in memory budget tests (tracemalloc overhead separation)
</verification>

<success_criteria>
1. Ratio assertions compare comp_het vectorized vs original within same run, asserting speedup > 1.0 (BENCH-04)
2. Memory budget tests use tracemalloc for all five components (BENCH-05)
3. Memory budget violations are warnings only, never hard failures
4. Timing tests and memory tests are in separate files (no tracemalloc in timing benchmarks)
5. All tests pass and produce human-readable console output
</success_criteria>

<output>
After completion, create `.planning/phases/06-benchmark-framework/06-03-SUMMARY.md`
</output>
