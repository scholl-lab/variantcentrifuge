---
phase: 09-inheritance-analysis-optimization
plan: 05
type: execute
wave: 5
depends_on: ["09-04"]
files_modified:
  - tests/performance/benchmark_inheritance.py
autonomous: true

must_haves:
  truths:
    - "Benchmarks prove 10-100x speedup on Pass 1 pattern deduction"
    - "No performance regressions on Pass 2 (compound het) or Pass 3 (prioritization)"
    - "All benchmark tests pass with ratio assertions"
  artifacts:
    - path: "tests/performance/benchmark_inheritance.py"
      provides: "Updated benchmarks comparing vectorized vs pre-vectorization baseline"
  key_links:
    - from: "tests/performance/benchmark_inheritance.py"
      to: "variantcentrifuge/inheritance/analyzer.py"
      via: "benchmarks analyze_inheritance with vectorized code"
      pattern: "analyze_inheritance"
---

<objective>
Benchmark the vectorized inheritance analysis to prove 10-100x speedup.

Purpose: Validate that the Phase 9 optimizations achieve the target speedup. Compare vectorized implementation against pre-vectorization baseline using the existing benchmark infrastructure from Phase 6.

Output: Updated benchmark results proving speedup targets are met.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/09-inheritance-analysis-optimization/09-CONTEXT.md
@.planning/phases/09-inheritance-analysis-optimization/09-04-SUMMARY.md
@tests/performance/benchmark_inheritance.py
@tests/performance/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Update benchmarks and measure vectorization speedup</name>
  <files>tests/performance/benchmark_inheritance.py</files>
  <action>
Update the existing benchmark infrastructure to measure the vectorization speedup:

**1. Read current benchmark_inheritance.py** to understand existing benchmark structure and fixtures.

**2. Add a direct comparison benchmark** that measures the old approach (df.apply with deduce_patterns_for_variant) vs the new approach (vectorized_deduce_patterns):

```python
@pytest.mark.slow
class TestPassOneVectorization:
    """Benchmark Pass 1: vectorized vs scalar pattern deduction."""

    def test_pass1_scalar_100(self, benchmark, inheritance_df_100):
        """Baseline: scalar deduce_patterns_for_variant via df.apply on 100 variants."""
        df, pedigree_data, sample_list = inheritance_df_100
        def scalar_pass1():
            return df.apply(
                lambda row: deduce_patterns_for_variant(row.to_dict(), pedigree_data, sample_list),
                axis=1
            )
        benchmark(scalar_pass1)

    def test_pass1_vectorized_100(self, benchmark, inheritance_df_100):
        """Vectorized: vectorized_deduce_patterns on 100 variants."""
        df, pedigree_data, sample_list = inheritance_df_100
        def vectorized_pass1():
            return vectorized_deduce_patterns(df, pedigree_data, sample_list)
        benchmark(vectorized_pass1)
```

Create similar pairs for 1K and 10K variants.

**3. Add ratio assertions** (following Phase 6 pattern):
```python
def test_vectorization_speedup_ratio(self):
    """Assert vectorized Pass 1 is at least 10x faster than scalar."""
    # Run both, compare times
    # Use the same approach as existing ratio assertions in benchmark files
```

**4. Run the benchmarks:**
```bash
pytest tests/performance/benchmark_inheritance.py -v --benchmark-only
```

**5. Record results** in the benchmark output. Compare against the Phase 7 baseline:
- Phase 7 baseline: 10K variants = 3.2s
- Target: 10K variants < 320ms (10x) to < 32ms (100x)

**6. If benchmarks show less than 10x improvement:**
- Profile to identify remaining bottleneck
- Check if genotype encoding is being repeated
- Verify numpy operations are truly vectorized (not being called per-row)
- Document actual speedup achieved

**7. Update any existing canary assertions** that may need new thresholds post-vectorization.

Note: The existing benchmark infrastructure uses pytest-benchmark. Follow the patterns established in Phase 6 for fixture creation, benchmark parameterization, and ratio assertions. Do NOT create new benchmark infrastructure -- extend the existing one.
  </action>
  <verify>
    Run: `pytest tests/performance/benchmark_inheritance.py -v --benchmark-only -k "pass1"` -- benchmarks run and show timing
    Run: `pytest tests/performance/benchmark_inheritance.py -v -k "ratio"` -- ratio assertions pass (vectorized >= 10x faster)
    Run: `pytest -m unit` -- no regressions
  </verify>
  <done>Benchmarks prove 10x+ speedup on Pass 1, ratio assertions pass, results documented</done>
</task>

<task type="auto">
  <name>Task 2: Run full benchmark suite and document Phase 9 results</name>
  <files>tests/performance/benchmark_inheritance.py</files>
  <action>
**1. Run the full inheritance benchmark suite** (not just Pass 1):
```bash
pytest tests/performance/benchmark_inheritance.py -v --benchmark-only --benchmark-save=phase9_vectorization
```

**2. Compare with Phase 7 baseline** (if available):
```bash
pytest tests/performance/benchmark_inheritance.py -v --benchmark-only --benchmark-compare=0001_phase7_quick_wins
```

**3. Record key metrics:**

| Component | Scale | Phase 7 Baseline | Phase 9 Result | Improvement |
|-----------|-------|-------------------|----------------|-------------|
| Single variant deduce | 1 variant | 4.4 us | ? | ? |
| Inheritance analysis | 100 variants | 37 ms | ? | ? |
| Inheritance analysis | 1K variants | 346 ms | ? | ? |
| Inheritance analysis | 10K variants | 3.2 s | ? | ? |

**4. Verify no regressions** on compound het benchmarks (should be same or better since we removed the original fallback code).

**5. Run golden file validation one final time:**
```bash
python scripts/validate_inheritance.py compare
```

**6. Run full test suite one final time:**
```bash
pytest -m unit
pytest -m integration (if applicable)
```

**7. Log the results** in the summary with actual numbers.
  </action>
  <verify>
    Run: `pytest tests/performance/ -v --benchmark-only` -- all benchmarks pass
    Run: `python scripts/validate_inheritance.py compare` -- exit code 0
    Run: `pytest -m unit` -- all pass
    Run: `make ci-check` -- all CI checks pass
  </verify>
  <done>Full benchmark suite run, Phase 9 results documented, all tests pass, CI checks clean</done>
</task>

</tasks>

<verification>
1. `pytest tests/performance/benchmark_inheritance.py -v --benchmark-only` -- all benchmarks run
2. Pass 1 vectorized is >= 10x faster than scalar (ratio assertion passes)
3. No regressions on compound het or full analysis benchmarks
4. `python scripts/validate_inheritance.py compare` -- exit code 0
5. `pytest -m unit` -- all pass
6. `make ci-check` -- all CI checks pass
</verification>

<success_criteria>
- Benchmarks demonstrate 10-100x speedup on Pass 1 pattern deduction
- No performance regressions on other components
- All golden file scenarios still pass
- All tests pass including CI checks
- Phase 9 benchmark results documented for comparison with future phases
</success_criteria>

<output>
After completion, create `.planning/phases/09-inheritance-analysis-optimization/09-05-SUMMARY.md`
</output>
