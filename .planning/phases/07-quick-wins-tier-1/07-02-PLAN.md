---
phase: 07-quick-wins-tier-1
plan: 02
type: execute
wave: 2
depends_on: ["07-01"]
files_modified:
  - variantcentrifuge/gene_burden.py
  - variantcentrifuge/stats_engine.py
  - variantcentrifuge/stats.py
  - variantcentrifuge/stages/analysis_stages.py
  - variantcentrifuge/inheritance/parallel_analyzer.py
  - variantcentrifuge/inheritance/analyzer.py
  - tests/performance/benchmark_comp_het.py
  - tests/performance/benchmark_pipeline.py
  - scripts/create_cohort_report.py
  - variantcentrifuge/pipeline_core/runner.py
  - .pre-commit-config.yaml
autonomous: true

must_haves:
  truths:
    - "All 17 groupby call sites use observed=True"
    - "gc.collect() runs after every pipeline stage execution"
    - "Memory usage is logged at DEBUG level before and after each stage"
    - "Pre-commit hook catches new groupby calls missing observed=True"
  artifacts:
    - path: "variantcentrifuge/pipeline_core/runner.py"
      provides: "Memory-aware stage execution with gc.collect"
      contains: "gc.collect()"
    - path: ".pre-commit-config.yaml"
      provides: "Pre-commit hook enforcing observed=True in groupby"
      contains: "pandas-groupby-observed"
  key_links:
    - from: "variantcentrifuge/pipeline_core/runner.py"
      to: "gc module"
      via: "import gc; gc.collect() after stage execution"
      pattern: "gc\\.collect\\(\\)"
    - from: "variantcentrifuge/pipeline_core/runner.py"
      to: "psutil"
      via: "psutil.Process().memory_info()"
      pattern: "psutil\\.Process"
---

<objective>
Add observed=True to all 17 groupby call sites and add gc.collect() with memory logging between pipeline stages.

Purpose: QWIN-02 adds `observed=True` to all groupby calls to prevent categorical dtype slowdowns when Phase 8 introduces categorical columns. QWIN-04 adds gc.collect() after every pipeline stage to free intermediate memory, with debug-level logging of memory before/after each stage via psutil.
Output: All groupby calls future-proofed, pipeline runner with memory-aware stage transitions, pre-commit hook preventing regressions.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/07-quick-wins-tier-1/07-RESEARCH.md
@.planning/phases/07-quick-wins-tier-1/07-01-SUMMARY.md
@variantcentrifuge/pipeline_core/runner.py
@.pre-commit-config.yaml
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add observed=True to all 17 groupby call sites</name>
  <files>variantcentrifuge/gene_burden.py, variantcentrifuge/stats_engine.py, variantcentrifuge/stats.py, variantcentrifuge/stages/analysis_stages.py, variantcentrifuge/inheritance/parallel_analyzer.py, variantcentrifuge/inheritance/analyzer.py, tests/performance/benchmark_comp_het.py, tests/performance/benchmark_pipeline.py, scripts/create_cohort_report.py</files>
  <action>
  Add `observed=True` to all 17 groupby call sites identified in the research. This is an atomic change — update all sites in one pass.

  IMPORTANT: Do NOT rely on specific line numbers — Plan 07-01 will have modified gene_burden.py before this plan runs, shifting all line numbers. For EACH file, use `grep -n "\.groupby("` to find the actual current line numbers before editing.

  The files and approximate call sites (use grep to find exact locations):

  1. `variantcentrifuge/gene_burden.py` — `df.groupby("GENE")` -> `df.groupby("GENE", observed=True)`
  2. `variantcentrifuge/stats_engine.py` — two `df.groupby(groupby_cols)` calls -> add `observed=True`
  3. `variantcentrifuge/stats.py` — three groupby calls -> add `observed=True`
  4. `variantcentrifuge/stages/analysis_stages.py` — one groupby call -> add `observed=True`
  5. `variantcentrifuge/inheritance/parallel_analyzer.py` — two groupby calls -> add `observed=True`
  6. `variantcentrifuge/inheritance/analyzer.py` — two groupby calls -> add `observed=True`
  7. `tests/performance/benchmark_comp_het.py` — one groupby call -> add `observed=True`
  8. `tests/performance/benchmark_pipeline.py` — three groupby calls -> add `observed=True`
  9. `scripts/create_cohort_report.py` — two groupby calls -> add `observed=True`

  After all edits, verify NO groupby calls remain without observed=True:
  ```bash
  grep -rn "\.groupby(" variantcentrifuge/ scripts/ tests/ --include="*.py" | grep -v "observed=True" | grep -v "__pycache__"
  ```
  This command must return empty.

  If any test fails after adding observed=True to a specific call site, revert THAT site only and add a comment: `# TODO(phase-08): add observed=True after categorical dtype migration`. This should not happen since no categorical dtypes exist yet.

  Run `pytest -m unit -x` and `pytest -m integration -x` to verify no behavior changes.
  </action>
  <verify>
  `grep -rn "\.groupby(" variantcentrifuge/ scripts/ tests/ --include="*.py" | grep -v "observed=True" | grep -v "__pycache__"` returns empty
  `pytest -m unit -x` passes
  `make lint` passes
  </verify>
  <done>All 17 groupby call sites updated with observed=True. No behavioral changes (confirmed by full test suite). Codebase is ready for Phase 8 categorical dtype introduction.</done>
</task>

<task type="auto">
  <name>Task 2: Add gc.collect() with memory logging to pipeline runner + pre-commit hook</name>
  <files>variantcentrifuge/pipeline_core/runner.py, .pre-commit-config.yaml</files>
  <action>
  Part A — Memory-aware stage execution in runner.py:

  Modify `_execute_stage()` method in `variantcentrifuge/pipeline_core/runner.py`. Use `grep -n "_execute_stage" variantcentrifuge/pipeline_core/runner.py` to find the exact location. Add imports at top of file: `import gc` and `import psutil`.

  Transform the method to:
  1. Before stage execution: if logger is at DEBUG level, capture RSS memory via `psutil.Process().memory_info().rss / 1024 / 1024` and log it
  2. After stage execution (after timing capture): call `gc.collect()`
  3. After gc.collect(): if DEBUG, capture memory again and log the delta

  Follow the exact pattern from 07-RESEARCH.md "Verified Pattern 4: Memory Logging Integration":
  ```python
  def _execute_stage(self, stage: Stage, context: PipelineContext) -> PipelineContext:
      start_time = time.time()

      mem_before_mb = None
      if logger.isEnabledFor(logging.DEBUG):
          process = psutil.Process()
          mem_before_mb = process.memory_info().rss / 1024 / 1024
          logger.debug(f"[{stage.name}] Starting - Memory: {mem_before_mb:.1f} MB")

      result = stage(context)
      elapsed = time.time() - start_time
      self._execution_times[stage.name] = elapsed

      if hasattr(stage, "subtask_times") and stage.subtask_times:
          self._subtask_times[stage.name] = stage.subtask_times

      gc.collect()

      if mem_before_mb is not None:
          process = psutil.Process()
          mem_after_mb = process.memory_info().rss / 1024 / 1024
          freed_mb = mem_before_mb - mem_after_mb
          logger.debug(
              f"[{stage.name}] Complete in {elapsed:.1f}s - "
              f"Memory: {mem_after_mb:.1f} MB (freed {freed_mb:.1f} MB)"
          )

      return result
  ```

  IMPORTANT: Keep the existing method signature and docstring. Only modify the body. The `gc.collect()` call MUST run unconditionally (not just in DEBUG mode) — only the memory logging is conditional on DEBUG.

  Part B — Pre-commit hook for groupby enforcement:

  Add a local hook to `.pre-commit-config.yaml` that catches new groupby calls without `observed=True`. Add this after the existing ruff hooks:

  ```yaml
  -   repo: local
      hooks:
      -   id: pandas-groupby-observed
          name: Enforce observed=True in groupby
          entry: bash -c 'if grep -rn "\.groupby(" --include="*.py" variantcentrifuge/ scripts/ | grep -v "observed=True" | grep -v "^Binary"; then echo "ERROR: groupby() calls must include observed=True"; exit 1; fi'
          language: system
          pass_filenames: false
          types: [python]
  ```

  After adding the hook, verify it actually works by running:
  ```bash
  pre-commit run pandas-groupby-observed --all-files
  ```
  The hook should pass (exit 0) since all groupby calls were already updated in Task 1.

  Run `make lint` and `make typecheck` to verify no issues.
  </action>
  <verify>
  `grep -n "gc.collect()" variantcentrifuge/pipeline_core/runner.py` returns a match
  `grep -n "psutil.Process" variantcentrifuge/pipeline_core/runner.py` returns a match
  `grep -n "pandas-groupby-observed" .pre-commit-config.yaml` returns a match
  `pre-commit run pandas-groupby-observed --all-files` passes (exit 0)
  `pytest -m unit -x` passes
  `make lint` passes
  `make typecheck` passes (psutil types available)
  </verify>
  <done>gc.collect() runs after every pipeline stage. Memory before/after logged at DEBUG level via psutil. Pre-commit hook prevents new groupby calls without observed=True in variantcentrifuge/ and scripts/. Hook verified working via pre-commit run.</done>
</task>

</tasks>

<verification>
- `grep -rn "\.groupby(" variantcentrifuge/ scripts/ tests/ --include="*.py" | grep -v "observed=True" | grep -v "__pycache__"` — returns empty
- `grep -c "gc.collect" variantcentrifuge/pipeline_core/runner.py` — returns 1+
- `pre-commit run pandas-groupby-observed --all-files` — passes
- `pytest -m unit -x` — all unit tests pass
- `pytest -m integration -x` — all integration tests pass
- `make lint && make typecheck` — clean
</verification>

<success_criteria>
1. All 17 groupby call sites have observed=True
2. No groupby call anywhere in variantcentrifuge/ or scripts/ is missing observed=True
3. gc.collect() called after every stage execution in runner.py
4. Memory logging at DEBUG level shows before/after RSS for each stage
5. Pre-commit hook catches future groupby calls missing observed=True and verified working
6. All existing tests pass with no behavior changes
</success_criteria>

<output>
After completion, create `.planning/phases/07-quick-wins-tier-1/07-02-SUMMARY.md`
</output>
