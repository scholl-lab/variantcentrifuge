---
phase: 07-quick-wins-tier-1
plan: 03
type: execute
wave: 2
depends_on: ["07-01", "07-02"]
files_modified:
  - .planning/performance-analysis-report.md
autonomous: true

must_haves:
  truths:
    - "All existing tests pass after both Plan 01 and Plan 02 changes"
    - "Gene burden benchmarks show measurable speedup from dead code removal"
    - "Performance analysis report updated with before/after numbers"
  artifacts:
    - path: ".planning/performance-analysis-report.md"
      provides: "Updated performance record with Phase 7 before/after benchmarks"
      contains: "Phase 7"
  key_links:
    - from: "tests/performance/benchmark_gene_burden.py"
      to: "variantcentrifuge/gene_burden.py"
      via: "Benchmark measures gene burden performance"
      pattern: "benchmark"
---

<objective>
Run full benchmark suite to verify speedup and update performance records.

Purpose: Phase 7 success criteria #5 requires benchmarks showing 30-40% speedup on gene burden analysis. This plan runs the complete Phase 6 benchmark suite, compares against the v0.12.1 baseline, and updates the performance analysis report with before/after numbers.
Output: Benchmark results proving improvement, updated performance-analysis-report.md.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/performance-analysis-report.md
@.planning/phases/07-quick-wins-tier-1/07-01-SUMMARY.md
@.planning/phases/07-quick-wins-tier-1/07-02-SUMMARY.md
</context>

<tasks>

<task type="auto">
  <name>Task 1: Run full test suite and benchmark comparison</name>
  <files>.planning/performance-analysis-report.md</files>
  <action>
  Step 1 — Run full test suite to verify all optimizations work together:
  ```bash
  pytest -m "not slow" -x
  ```
  This must pass with zero failures. If any test fails, diagnose and report — do NOT proceed to benchmarks.

  Step 2 — Run the full benchmark suite:
  ```bash
  pytest tests/performance/ -v --benchmark-autosave
  ```
  This runs all 60 benchmark tests from Phase 6 and auto-saves results.

  Step 3 — Run gene burden benchmarks specifically to measure the dead code removal impact:
  ```bash
  pytest tests/performance/benchmark_gene_burden.py -v --benchmark-compare
  ```
  Compare against the baseline saved in `.benchmarks/`. The dead code removal should show 20-30% improvement on gene burden benchmarks.

  Step 4 — Update `.planning/performance-analysis-report.md`:
  Add a new section "## Phase 7: Quick Wins - Tier 1 Results" with:
  - Date of benchmark run
  - Table of before/after numbers for gene burden at each scale (100, 1K, 10K variants)
  - Table of any other notable improvements or regressions
  - Summary of optimizations applied (dead code removal, groupby observed=True, temp file fixes, gc.collect)
  - Note that observed=True shows no immediate speedup (expected — no categorical dtypes yet, prepares for Phase 8)
  - Note gc.collect impact on memory (if measurable from benchmark memory tests)

  If benchmarks show LESS than 20% improvement on gene burden, document the actual numbers and note that the dead code loop may have less impact than estimated. Do NOT fabricate numbers.

  If any benchmark shows a REGRESSION of more than 5%, investigate and document the cause.
  </action>
  <verify>
  `pytest -m "not slow" -x` passes with zero failures
  `pytest tests/performance/ -v` completes without errors
  `.planning/performance-analysis-report.md` contains "Phase 7" section with actual benchmark numbers
  </verify>
  <done>Full test suite passes. Benchmarks run and compared against v0.12.1 baseline. Performance analysis report updated with actual before/after numbers documenting the impact of Phase 7 optimizations.</done>
</task>

</tasks>

<verification>
- `pytest -m "not slow" -x` — all tests pass
- `pytest tests/performance/` — all benchmarks complete
- `.planning/performance-analysis-report.md` updated with Phase 7 results section
</verification>

<success_criteria>
1. Zero test failures across the entire test suite
2. Gene burden benchmarks show measurable improvement (target: 30-40%)
3. No benchmark regressions exceeding 5%
4. Performance analysis report contains actual measured numbers (not estimates)
</success_criteria>

<output>
After completion, create `.planning/phases/07-quick-wins-tier-1/07-03-SUMMARY.md`
</output>
