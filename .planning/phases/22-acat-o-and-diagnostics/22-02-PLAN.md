---
phase: 22-acat-o-and-diagnostics
plan: 02
type: execute
wave: 2
depends_on: ["22-01"]
files_modified:
  - variantcentrifuge/association/diagnostics.py
  - variantcentrifuge/stages/analysis_stages.py
  - variantcentrifuge/cli.py
autonomous: true

must_haves:
  truths:
    - "Lambda_GC is computed per active test and written to lambda_gc.tsv in diagnostics directory"
    - "QQ data TSV contains observed vs expected -log10(p) per test"
    - "Summary.txt contains sample sizes, active tests, lambda_GC values, and warning counts"
    - "Pipeline logs warning when n_cases < 200 or case:control > 1:20"
    - "Per-gene warnings column flags genes with case_carriers < min_case_carriers"
    - "--diagnostics-output CLI arg creates the diagnostics directory"
  artifacts:
    - path: "variantcentrifuge/association/diagnostics.py"
      provides: "compute_lambda_gc(), compute_qq_data(), emit_sample_size_warnings(), write_diagnostics()"
      contains: "compute_lambda_gc"
    - path: "variantcentrifuge/cli.py"
      provides: "--diagnostics-output CLI argument"
      contains: "diagnostics-output"
    - path: "variantcentrifuge/stages/analysis_stages.py"
      provides: "Diagnostics integration in AssociationAnalysisStage._process()"
      contains: "diagnostics_output"
  key_links:
    - from: "variantcentrifuge/stages/analysis_stages.py"
      to: "variantcentrifuge/association/diagnostics.py"
      via: "lazy import and call after engine.run_all()"
      pattern: "from.*diagnostics.*import"
    - from: "variantcentrifuge/cli.py"
      to: "variantcentrifuge/stages/analysis_stages.py"
      via: "diagnostics_output config key"
      pattern: "diagnostics.output"
---

<objective>
Implement the diagnostics module (lambda_GC, QQ data, sample size warnings, summary) and integrate it into the pipeline via CLI arg and stage post-processing.

Purpose: Diagnostics enable users to assess calibration (lambda_GC near 1.0), visualize p-value distributions (QQ data), and identify underpowered analyses (sample size warnings). These are standard genomics QC outputs.

Output: `diagnostics.py` module, `--diagnostics-output` CLI arg, stage integration writing diagnostics files after association analysis completes.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/22-acat-o-and-diagnostics/22-RESEARCH.md
@.planning/phases/22-acat-o-and-diagnostics/22-CONTEXT.md
@.planning/phases/22-acat-o-and-diagnostics/22-01-SUMMARY.md
@variantcentrifuge/association/engine.py
@variantcentrifuge/association/base.py
@variantcentrifuge/stages/analysis_stages.py
@variantcentrifuge/cli.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Diagnostics module</name>
  <files>
    variantcentrifuge/association/diagnostics.py
  </files>
  <action>
    Create `variantcentrifuge/association/diagnostics.py` with:

    1. Module-level constant: `_EXPECTED_CHI2_MEDIAN = 0.45493642311957174` (from `chi2.ppf(0.5, df=1)` — hardcode the exact value, do NOT call chi2.ppf at import time).

    2. `compute_lambda_gc(p_values: list[float | None]) -> float | None`:
       - Filter out None and NaN values; clip to [1e-300, 1.0 - 1e-15]
       - Return None if fewer than 2 valid p-values
       - Convert to chi2: `chi2_dist.isf(valid, df=1)`
       - Return `float(np.median(chi2_obs) / _EXPECTED_CHI2_MEDIAN)`
       - Log WARNING if n_valid < 100: "lambda_GC computed on {n} tests — unreliable for n < 100"

    3. `compute_qq_data(p_values: list[float | None], test_name: str) -> pd.DataFrame`:
       - Filter out None/NaN, sort ascending
       - Hazen quantile formula for expected: `i / (n + 1)` for rank i in 1..n
       - Compute -log10 for both expected and observed (clip observed to [1e-300, 1.0])
       - Return DataFrame with columns: "test", "expected_neg_log10_p", "observed_neg_log10_p"
       - Sort by expected_neg_log10_p ascending (smallest values first = non-significant end)
       - Return empty DataFrame with same columns if no valid p-values

    4. `emit_sample_size_warnings(n_cases: int, n_controls: int, config: AssociationConfig) -> list[str]`:
       - Check n_cases < config.min_cases: append "LOW_CASE_COUNT" warning
       - Check n_controls/n_cases > config.max_case_control_ratio: append "IMBALANCED_COHORT"
       - Log each warning via logger.warning()
       - Return list of warning flag strings

    5. `compute_per_gene_warnings(gene: str, case_carriers: int, config: AssociationConfig) -> list[str]`:
       - Check case_carriers < config.min_case_carriers: append "LOW_CARRIER_COUNT"
       - Log WARNING for each flagged gene
       - Return list of warning flag strings

    6. `write_diagnostics(results_df: pd.DataFrame, diagnostics_dir: str | Path, test_names: list[str], n_cases: int, n_controls: int, cohort_warnings: list[str]) -> None`:
       - Create diagnostics_dir with `Path.mkdir(parents=True, exist_ok=True)`
       - Write `lambda_gc.tsv`: columns "test_name", "lambda_gc", "n_tests" — one row per test with valid p-values. Column detection: look for `{test_name}_p_value` columns in results_df, plus `acat_o_p_value`.
       - Write `qq_data.tsv`: concatenated QQ data for all tests (same column detection). Single file with "test" column to filter by.
       - Write `summary.txt`: human-readable text with:
         - Header: "Association Analysis Diagnostics Summary"
         - Sample sizes: n_cases, n_controls
         - Active tests listed
         - Lambda_GC per test (formatted to 4 decimal places)
         - Cohort-level warnings (if any)
         - Count of genes flagged with warnings
         - Note about lambda_GC reliability if n_tests < 100
       - Log INFO: "Diagnostics written to {diagnostics_dir}"

    Use `scipy.stats.chi2` (import as `chi2_dist`), `numpy`, `pandas`, `pathlib.Path`, `logging`.
  </action>
  <verify>
    Run: `python -c "
from variantcentrifuge.association.diagnostics import compute_lambda_gc, compute_qq_data
import numpy as np
# Uniform p-values should give lambda_GC ~ 1.0
np.random.seed(42)
uniform_p = np.random.uniform(0, 1, 1000).tolist()
lam = compute_lambda_gc(uniform_p)
print(f'Lambda_GC (uniform): {lam:.4f}')
assert 0.9 < lam < 1.1, f'Expected ~1.0, got {lam}'
# QQ data shape
qq = compute_qq_data(uniform_p, 'test')
print(f'QQ data shape: {qq.shape}')
assert qq.shape[0] == 1000
assert list(qq.columns) == ['test', 'expected_neg_log10_p', 'observed_neg_log10_p']
print('All checks passed')
"`
  </verify>
  <done>
    compute_lambda_gc returns ~1.0 for uniform p-values.
    compute_qq_data produces correctly shaped DataFrame with ascending sort.
    write_diagnostics creates all three output files.
  </done>
</task>

<task type="auto">
  <name>Task 2: CLI arg + stage integration for diagnostics and per-gene warnings</name>
  <files>
    variantcentrifuge/cli.py
    variantcentrifuge/stages/analysis_stages.py
  </files>
  <action>
    **In `variantcentrifuge/cli.py`:**

    1. Add `--diagnostics-output` CLI argument in the Association Analysis group (after the existing `--trait-type` arg, around line 462):
       ```python
       stats_group.add_argument(
           "--diagnostics-output",
           type=str,
           default=None,
           help=(
               "Path to directory for diagnostics output (lambda_GC, QQ data, summary). "
               "Created automatically if it does not exist."
           ),
       )
       ```

    2. In the config mapping section (around line 1084-1088), add:
       ```python
       cfg["diagnostics_output"] = getattr(args, "diagnostics_output", None)
       ```

    3. Add validation: if `--diagnostics-output` is provided without `--perform-association`, call `parser.error()`:
       ```python
       if getattr(args, "diagnostics_output", None) and not args.perform_association:
           parser.error("--diagnostics-output requires --perform-association to be set")
       ```

    **In `variantcentrifuge/stages/analysis_stages.py` (`AssociationAnalysisStage._process()`):**

    1. Pass `diagnostics_output` to AssociationConfig construction (around line 2121-2133):
       ```python
       diagnostics_output=context.config.get("diagnostics_output"),
       min_cases=context.config.get("association_min_cases", 200),
       max_case_control_ratio=context.config.get("association_max_case_control_ratio", 20.0),
       min_case_carriers=context.config.get("association_min_case_carriers", 10),
       ```

    2. After `results_df = engine.run_all(gene_burden_data)` and the results check, add per-gene warning computation:
       - Build a lookup dict BEFORE calling engine.run_all():
         ```python
         gene_data_by_gene = {d['gene']: d for d in gene_burden_data}
         ```
       - After engine.run_all() returns results_df, iterate unique genes in results_df:
         ```python
         from variantcentrifuge.association.diagnostics import compute_per_gene_warnings
         warnings_by_gene = {}
         for gene in results_df["gene"].unique():
             gdata = gene_data_by_gene.get(gene, {})
             case_carriers = gdata.get("proband_carrier_count", 0)
             gene_warnings = compute_per_gene_warnings(gene, case_carriers, assoc_config)
             if gene_warnings:
                 warnings_by_gene[gene] = ";".join(gene_warnings)
         results_df["warnings"] = results_df["gene"].map(warnings_by_gene).fillna("")
         ```
       - Also collect cohort-level warnings using `emit_sample_size_warnings()`
       - Add the warnings column to results_df before writing TSV

    3. After writing the association TSV, add diagnostics output:
       ```python
       if assoc_config.diagnostics_output:
           from variantcentrifuge.association.diagnostics import write_diagnostics, emit_sample_size_warnings
           cohort_warnings = emit_sample_size_warnings(n_cases_total, n_controls_total, assoc_config)
           write_diagnostics(
               results_df=results_df,
               diagnostics_dir=assoc_config.diagnostics_output,
               test_names=test_names,
               n_cases=n_cases_total,
               n_controls=n_controls_total,
               cohort_warnings=cohort_warnings,
           )
       ```

    4. Update the existing sample-size warning section (lines ~2196-2221) to use the AssociationConfig thresholds instead of hardcoded values. The existing warnings at n<10 (abort) and n<50 (warning) should remain as-is since those are extreme edge cases. The DIAG-06 warnings (n<200, ratio>20) should use config thresholds.

    IMPORTANT: The lazy import pattern must be used for diagnostics (same as covariates import pattern already in this file). Do NOT add top-level imports.
  </action>
  <verify>
    Run: `python -c "
from variantcentrifuge.cli import main
# Verify the arg is registered (won't actually run the pipeline)
import argparse
import sys
sys.argv = ['variantcentrifuge', '--help']
try:
    main()
except SystemExit:
    pass
" 2>&1 | grep -i diagnostics`

    Run: `pytest tests/unit/test_association_stage.py -x -q`
  </verify>
  <done>
    --diagnostics-output CLI arg is available and maps to config.
    AssociationAnalysisStage writes diagnostics files when diagnostics_output is set.
    Per-gene warnings column appears in results TSV.
    Cohort-level warnings logged and included in summary.txt.
    Existing stage tests pass.
  </done>
</task>

</tasks>

<verification>
1. `--diagnostics-output /tmp/diag` creates the directory with lambda_gc.tsv, qq_data.tsv, summary.txt
2. lambda_gc.tsv has columns: test_name, lambda_gc, n_tests
3. qq_data.tsv has columns: test, expected_neg_log10_p, observed_neg_log10_p
4. summary.txt is human-readable with sample sizes and lambda_GC values
5. Per-gene warnings column in association TSV contains semicolon-separated flags
6. `pytest tests/unit/test_association_stage.py -x -q` passes
</verification>

<success_criteria>
- Diagnostics module produces correct lambda_GC (~1.0 for calibrated tests)
- QQ data sorted correctly for plotting (ascending expected)
- CLI integration allows `--diagnostics-output` with proper validation
- Stage writes diagnostics after association analysis completes
- Per-gene and cohort-level warnings are emitted and recorded
</success_criteria>

<output>
After completion, create `.planning/phases/22-acat-o-and-diagnostics/22-02-SUMMARY.md`
</output>
