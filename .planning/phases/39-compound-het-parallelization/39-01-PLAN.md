---
phase: 39-compound-het-parallelization
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - tests/performance/standalone_bench_comp_het_parallel.py
autonomous: true

must_haves:
  truths:
    - "A standalone benchmark script exists that exercises compound het Pass 2 with realistic synthetic data"
    - "The benchmark measures wall-time for Pass 2 across multiple min_variants_for_parallel thresholds and worker counts"
    - "Running the script produces a timing table printed to stdout — no assertion thresholds, human reviews the numbers"
  artifacts:
    - path: "tests/performance/standalone_bench_comp_het_parallel.py"
      provides: "Standalone synthetic benchmark for comp het parallelization"
      contains: "analyze_inheritance_parallel"
  key_links:
    - from: "tests/performance/standalone_bench_comp_het_parallel.py"
      to: "variantcentrifuge/inheritance/parallel_analyzer.py"
      via: "import analyze_inheritance_parallel"
      pattern: "from variantcentrifuge\\.inheritance\\.parallel_analyzer import"
---

<objective>
Create a standalone synthetic benchmark script that measures compound het Pass 2 performance and capture baseline timing before any optimization.

Purpose: CONTEXT.md mandates "profile first, then optimize." This plan builds the measurement tool and records the pre-optimization baseline so Plan 02 can validate speedup.

Output: `tests/performance/standalone_bench_comp_het_parallel.py` — a runnable script that generates synthetic data (1000 genes, 10000 variants, skewed distribution), times Pass 2 with different configurations, and prints a comparison table.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/39-compound-het-parallelization/39-CONTEXT.md
@.planning/phases/39-compound-het-parallelization/39-RESEARCH.md
@variantcentrifuge/inheritance/parallel_analyzer.py
@variantcentrifuge/inheritance/comp_het_vectorized.py
@tests/performance/helpers/synthetic_data.py
@tests/performance/benchmark_parallelism.py
@tests/performance/conftest.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create standalone synthetic benchmark script</name>
  <files>tests/performance/standalone_bench_comp_het_parallel.py</files>
  <action>
Create a standalone Python script (NOT a pytest test) at `tests/performance/standalone_bench_comp_het_parallel.py`.

The script should:

1. **Generate synthetic data** with a realistic skewed gene distribution:
   - Target: ~1000 genes, ~10000 total variants
   - Skewed: a few genes with 50-200 variants (like PKD1), many genes with 2-5 variants
   - Use `tests/performance/helpers/synthetic_data.py` if it has suitable generators (`generate_synthetic_variants`, `generate_synthetic_pedigree`). If those helpers don't generate compound-het-ready data (with proper CHROM/POS/REF/ALT columns and per-sample GT columns), build the data inline.
   - Need: a DataFrame with columns CHROM, POS, REF, ALT, GENE, and per-sample genotype columns (e.g., GEN_0__GT, GEN_1__GT, etc.)
   - Need: pedigree_data dict with 3-10 samples in trios (proband + father + mother), some affected, some unaffected
   - Genotypes should include a realistic mix: ~60% 0/0, ~25% 0/1, ~10% 1/1, ~5% ./.

2. **Benchmark Pass 2 timing** by calling `analyze_inheritance_parallel()` with different configurations:
   - Sweep `min_variants_for_parallel` at: [25, 50, 100, 200, 500]
   - Sweep worker counts at: [1, 2, 4] (and max available CPUs if > 4)
   - Also measure sequential path (set min_variants_for_parallel very high to force sequential)
   - Each config: run 3 times, report median wall-time
   - Time ONLY Pass 2 (compound het analysis), not the full function. To isolate Pass 2, either:
     a. Use the existing `pass_times` dict logged at DEBUG level (capture via a logging handler), OR
     b. Wrap the call and measure total time (Pass 1 + Pass 2 + Pass 3) since Pass 1 and Pass 3 are fast relative to Pass 2 for large datasets

3. **Print results** as a formatted table to stdout:
   ```
   Compound Het Pass 2 Benchmark
   ==============================
   Dataset: 1000 genes, 10000 variants, 6 samples (2 trios)

   Configuration                    | Median (s) | Min (s) | Max (s)
   -------------------------------- | ---------- | ------- | -------
   sequential                       | ...        | ...     | ...
   parallel (workers=1, threshold=100) | ...     | ...     | ...
   parallel (workers=2, threshold=100) | ...     | ...     | ...
   ...
   ```

4. **No assertions** — this is a measurement script, not a test. Exit 0 always.

5. Make it executable with `#!/usr/bin/env python3` and include a `if __name__ == "__main__":` guard.

6. Add `sys.path.insert(0, ...)` to handle running from the project root without installation.

Important: Do NOT import from `tests.performance.helpers.synthetic_data` unless you confirm the helpers generate the right data shape. If they don't, generate data inline. The benchmark must be self-contained and runnable with `python tests/performance/standalone_bench_comp_het_parallel.py`.
  </action>
  <verify>
Run the benchmark script and confirm it produces output:
```bash
cd /mnt/c/development/scholl-lab/variantcentrifuge
python tests/performance/standalone_bench_comp_het_parallel.py
```
Should print a timing table to stdout and exit 0. Timing values will vary by machine.
  </verify>
  <done>Script runs without error, prints a timing comparison table with sequential and parallel configurations, and exits 0.</done>
</task>

<task type="auto">
  <name>Task 2: Capture baseline timing and verify existing tests pass</name>
  <files></files>
  <action>
1. Run the benchmark script and save the output to `.planning/phases/39-compound-het-parallelization/39-BASELINE.txt`:
   ```bash
   python tests/performance/standalone_bench_comp_het_parallel.py | tee .planning/phases/39-compound-het-parallelization/39-BASELINE.txt
   ```

2. Run `make ci-check` to confirm the codebase is clean before optimization begins.

3. Run the existing compound het tests specifically:
   ```bash
   pytest tests/test_inheritance/ -m comp_het -v --tb=short
   ```
   Confirm all pass.

This establishes the pre-optimization baseline that Plan 02 will compare against.
  </action>
  <verify>
- `.planning/phases/39-compound-het-parallelization/39-BASELINE.txt` exists and contains timing data
- `make ci-check` passes
- Compound het tests all pass
  </verify>
  <done>Baseline timing captured in 39-BASELINE.txt. All existing tests pass. Codebase is confirmed clean before optimization.</done>
</task>

</tasks>

<verification>
- `python tests/performance/standalone_bench_comp_het_parallel.py` runs and prints timing table
- `.planning/phases/39-compound-het-parallelization/39-BASELINE.txt` contains baseline timing
- `make ci-check` passes
- `pytest tests/test_inheritance/ -m comp_het` all pass
</verification>

<success_criteria>
1. Standalone benchmark script exists and runs without error
2. Baseline timing is captured before any code changes
3. All existing compound het tests pass (confirming clean starting point)
</success_criteria>

<output>
After completion, create `.planning/phases/39-compound-het-parallelization/39-01-SUMMARY.md`
</output>
