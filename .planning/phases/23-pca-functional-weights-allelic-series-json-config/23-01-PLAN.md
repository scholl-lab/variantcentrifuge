---
phase: 23-pca-functional-weights-allelic-series-json-config
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - variantcentrifuge/association/pca.py
  - variantcentrifuge/association/covariates.py
  - variantcentrifuge/association/base.py
  - variantcentrifuge/stages/processing_stages.py
  - variantcentrifuge/stages/stage_registry.py
  - variantcentrifuge/stages/analysis_stages.py
  - variantcentrifuge/cli.py
  - tests/unit/test_pca.py
autonomous: true

must_haves:
  truths:
    - "User can load a PLINK .eigenvec file and have PCs merged as covariates"
    - "User can load an AKT output file and have PCs merged as covariates"
    - "User can specify --pca-tool akt and AKT runs as a pipeline stage"
    - "Missing AKT binary raises ToolNotFoundError (hard error, not skip)"
    - "Requesting >20 PCA components triggers a logged warning"
    - "PCA sample IDs are aligned to VCF sample order with validation"
  artifacts:
    - path: "variantcentrifuge/association/pca.py"
      provides: "PCA file parsing (3 formats) and covariate merge"
      exports: ["load_pca_file", "merge_pca_covariates"]
    - path: "variantcentrifuge/stages/processing_stages.py"
      provides: "PCAComputationStage wrapping AKT subprocess"
      contains: "class PCAComputationStage"
    - path: "tests/unit/test_pca.py"
      provides: "Unit tests for PCA parsing, alignment, merge, and AKT stage"
      min_lines: 100
  key_links:
    - from: "variantcentrifuge/stages/analysis_stages.py"
      to: "variantcentrifuge/association/pca.py"
      via: "load_pca_file + merge_pca_covariates called in _process()"
      pattern: "load_pca_file|merge_pca_covariates"
    - from: "variantcentrifuge/association/pca.py"
      to: "variantcentrifuge/association/covariates.py"
      via: "PCA matrix appended to covariate matrix"
      pattern: "merge_pca_covariates"
    - from: "variantcentrifuge/cli.py"
      to: "variantcentrifuge/stages/analysis_stages.py"
      via: "CLI args --pca-file, --pca-tool, --pca-components stored in context.config"
      pattern: "pca_file|pca_tool|pca_components"
---

<objective>
Implement PCA integration: file parsing for PLINK .eigenvec, AKT output, and generic TSV formats; PCAComputationStage wrapping AKT subprocess; CLI args; covariate merge; sample alignment validation.

Purpose: Enable population stratification correction via pre-computed or AKT-computed principal components merged as covariates for association tests.
Output: pca.py module, PCAComputationStage, CLI args, unit tests, stage integration.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/23-pca-functional-weights-allelic-series-json-config/23-CONTEXT.md
@.planning/phases/23-pca-functional-weights-allelic-series-json-config/23-RESEARCH.md

Key source files:
@variantcentrifuge/association/covariates.py
@variantcentrifuge/association/base.py
@variantcentrifuge/stages/processing_stages.py
@variantcentrifuge/stages/stage_registry.py
@variantcentrifuge/stages/analysis_stages.py (AssociationAnalysisStage._process around line 2102)
@variantcentrifuge/cli.py (association args around line 408)
@variantcentrifuge/pipeline_core/error_handling.py (ToolNotFoundError)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create pca.py module, extend AssociationConfig, add CLI args</name>
  <files>
    variantcentrifuge/association/pca.py
    variantcentrifuge/association/base.py
    variantcentrifuge/cli.py
  </files>
  <action>
    Create `variantcentrifuge/association/pca.py` with:

    1. **`load_pca_file(filepath, vcf_samples, n_components=10)`** returning `(np.ndarray, list[str])`:
       - Auto-detect format from file content:
         - PLINK .eigenvec (no header): first line has FID + IID + numeric columns; 2 sample ID columns before PCs. Always use IID (column index 1), NOT FID.
         - PLINK .eigenvec (with header): first line starts with `#FID` or `FID`; use IID column.
         - AKT stdout format: header-less, first column sample ID, remaining columns numeric (single ID column, not FID+IID). Rename P0,P1,... -> PC1,PC2,...
         - Generic TSV: first column is sample ID (string), remaining columns all numeric.
       - Use `csv.Sniffer` for delimiter detection (same pattern as covariates.py).
       - Slice to first `n_components` columns. If file has fewer PCs than requested, log warning and use available.
       - Warn (logger.warning) if n_components > 20.
       - Align to vcf_samples order: reindex, raise ValueError listing missing samples (same pattern as covariates.py step 4).
       - Return `(pc_matrix, ["PC1", "PC2", ...])` aligned to vcf_samples.

    2. **`merge_pca_covariates(pca_matrix, pca_col_names, covariate_matrix, covariate_col_names)`** returning `(np.ndarray, list[str])`:
       - If covariate_matrix is None, return pca_matrix and pca_col_names directly.
       - Otherwise, np.hstack the two matrices; concatenate column name lists.
       - Assert shapes match on axis 0 (n_samples).

    3. **Auto-detection heuristic** (private helper `_detect_pca_format(lines: list[str]) -> str`):
       - Read first 5 lines.
       - If first line starts with `#FID` or `FID` (case-insensitive): "plink_header"
       - If first non-empty line splits into parts where parts[0] and parts[1] are non-numeric and parts[2:] are numeric: "plink_nohdr" (two ID columns)
       - If first non-empty line splits into parts where parts[0] is non-numeric and parts[1:] are numeric: "akt_or_generic" (one ID column)
       - Default: "generic"

    Extend `AssociationConfig` in base.py with three new fields:
    ```python
    pca_file: str | None = None
    """Path to pre-computed PCA file (PLINK .eigenvec, AKT output, or generic TSV)."""

    pca_tool: str | None = None
    """PCA computation tool: 'akt' to invoke AKT as subprocess. None = use pre-computed file only."""

    pca_components: int = 10
    """Number of principal components to use. Default: 10. Warn if >20."""
    ```

    Add CLI args in cli.py stats_group (after --variant-weights, before Inheritance Analysis group):
    ```python
    stats_group.add_argument(
        "--pca-file", type=str, default=None,
        help="Path to pre-computed PCA file (PLINK .eigenvec, AKT output, or generic TSV)."
    )
    stats_group.add_argument(
        "--pca-tool", choices=["akt"], default=None,
        help="PCA computation tool. 'akt' invokes AKT as a pipeline stage."
    )
    stats_group.add_argument(
        "--pca-components", type=int, default=10,
        help="Number of principal components (default: 10). Warn if >20."
    )
    ```

    Add validation in cli.py after existing association validation:
    ```python
    if getattr(args, "pca_file", None) and not args.perform_association:
        parser.error("--pca-file requires --perform-association to be set")
    if getattr(args, "pca_tool", None) and not args.perform_association:
        parser.error("--pca-tool requires --perform-association to be set")
    ```

    Wire CLI args to context.config in the dict-building section of cli.py:
    ```python
    "pca_file": getattr(args, "pca_file", None),
    "pca_tool": getattr(args, "pca_tool", None),
    "pca_components": getattr(args, "pca_components", 10),
    ```
  </action>
  <verify>
    `python -c "from variantcentrifuge.association.pca import load_pca_file, merge_pca_covariates; print('OK')"` succeeds.
    `make lint` passes.
    `make format` passes.
  </verify>
  <done>
    pca.py has load_pca_file and merge_pca_covariates functions with auto-format detection.
    AssociationConfig has pca_file, pca_tool, pca_components fields.
    CLI has --pca-file, --pca-tool, --pca-components args.
  </done>
</task>

<task type="auto">
  <name>Task 2: PCAComputationStage, stage integration, and unit tests</name>
  <files>
    variantcentrifuge/stages/processing_stages.py
    variantcentrifuge/stages/stage_registry.py
    variantcentrifuge/stages/analysis_stages.py
    tests/unit/test_pca.py
  </files>
  <action>
    1. **PCAComputationStage** in processing_stages.py:
       - Add at end of file. Follow existing Stage subclass pattern.
       - `name`: "pca_computation"
       - `dependencies`: `{"bcftools_prefilter"}` (needs VCF file)
       - `parallel_safe`: True (subprocess, no rpy2)
       - `_process()`:
         - Skip if `context.config.get("pca_tool")` is None.
         - Check `shutil.which("akt")` — if missing, raise `ToolNotFoundError("akt", self.name)` (import from pipeline_core.error_handling). This is a HARD ERROR per CONTEXT.md decision.
         - Get VCF file from context (context.config.get("vcf_file") or context.config.get("input_vcf")).
         - Build command: `["akt", "pca", vcf_file, "-N", str(n_components)]`
         - Run via `subprocess.run(cmd, capture_output=True, text=True, check=True)`
         - Write stdout to temp file in workspace: `context.workspace.get_path("pca_eigenvec.txt")`
         - Store path: `context.config["pca_file"] = output_path`
         - Log info about PCA computation completion.
       - Error handling: CalledProcessError -> log and re-raise.

    2. **Register PCAComputationStage** in stage_registry.py:
       - Add to `_register_processing_stages()` import list.
       - Register: `register_stage(PCAComputationStage, "processing", ["pca_computation", "pca"], 15.0)`

    3. **Wire PCA into AssociationAnalysisStage._process()** in analysis_stages.py:
       - After building `assoc_config` (around line 2138), before engine creation:
       ```python
       # PCA integration: load PCA file and merge with covariates
       pca_file = context.config.get("pca_file")
       if pca_file:
           from variantcentrifuge.association.pca import load_pca_file, merge_pca_covariates
           vcf_samples = context.vcf_samples or []
           n_pcs = context.config.get("pca_components", 10)
           pca_matrix, pca_col_names = load_pca_file(pca_file, vcf_samples, n_components=n_pcs)

           # Load existing covariates if covariate_file specified
           cov_matrix, cov_names = None, []
           if assoc_config.covariate_file:
               from variantcentrifuge.association.covariates import load_covariates
               cov_matrix, cov_names = load_covariates(
                   assoc_config.covariate_file, vcf_samples,
                   assoc_config.covariate_columns, assoc_config.categorical_covariates
               )

           merged_matrix, merged_names = merge_pca_covariates(
               pca_matrix, pca_col_names, cov_matrix, cov_names
           )
           # Store merged covariates in context for downstream use
           context.config["_merged_covariate_matrix"] = merged_matrix
           context.config["_merged_covariate_names"] = merged_names
           logger.info(f"PCA: merged {len(pca_col_names)} PCs with {len(cov_names)} covariates -> {len(merged_names)} total columns")
       ```
       - Also add `pca_file`, `pca_tool`, `pca_components` to the assoc_config construction.

    4. **Unit tests** in tests/unit/test_pca.py:
       - Test `_detect_pca_format()` on sample PLINK, AKT, generic formats.
       - Test `load_pca_file()` with PLINK .eigenvec (FID+IID): verify IID used, not FID.
       - Test `load_pca_file()` with AKT format: single ID column, zero-indexed PCs.
       - Test `load_pca_file()` with generic TSV: header row, sample ID first.
       - Test `load_pca_file()` n_components slicing (request 5, file has 10 -> get 5).
       - Test `load_pca_file()` fewer PCs available: request 10, file has 3 -> get 3 with warning.
       - Test `load_pca_file()` >20 components triggers warning (use caplog).
       - Test sample alignment: VCF samples in different order -> output matches VCF order.
       - Test missing sample raises ValueError.
       - Test `merge_pca_covariates()` with None covariate matrix.
       - Test `merge_pca_covariates()` with existing covariate matrix -> correct hstack.
       - Test PCAComputationStage raises ToolNotFoundError when akt not in PATH (mock shutil.which).
       - Mark all tests with `@pytest.mark.unit`.
  </action>
  <verify>
    `pytest tests/unit/test_pca.py -v` passes all tests.
    `make lint && make format` passes.
    `make test-fast` passes (no regressions).
  </verify>
  <done>
    PCAComputationStage registered and functional (invokes AKT, stores path in context).
    AssociationAnalysisStage loads PCA file and merges with covariates.
    Unit tests cover all 3 PCA file formats, alignment, merge, >20 PC warning, and ToolNotFoundError.
    All existing tests pass.
  </done>
</task>

</tasks>

<verification>
1. `python -c "from variantcentrifuge.association.pca import load_pca_file, merge_pca_covariates"` imports cleanly
2. `pytest tests/unit/test_pca.py -v` — all PCA tests pass
3. `make test-fast` — no regressions in existing 1249+ tests
4. `make lint && make format` — clean
</verification>

<success_criteria>
- PCA file parsing handles PLINK .eigenvec (FID+IID), AKT output, and generic TSV with auto-detection
- Sample alignment to VCF order is verified with ValueError on missing samples
- PCAComputationStage raises ToolNotFoundError (hard error) when AKT is not in PATH
- >20 PCA components triggers logged warning
- PCA columns merge correctly with existing covariates (or standalone if no covariates)
- All unit tests pass; no regressions
</success_criteria>

<output>
After completion, create `.planning/phases/23-pca-functional-weights-allelic-series-json-config/23-01-SUMMARY.md`
</output>
