---
phase: 21-pure-python-skat-backend
plan: 03
type: execute
wave: 3
depends_on: ["21-02"]
files_modified:
  - tests/unit/test_davies_pvalue.py
  - tests/unit/test_skat_python_backend.py
  - tests/unit/test_skat_python_comparison.py
autonomous: true

must_haves:
  truths:
    - "Liu p-values are validated against known chi-squared mixture results"
    - "Kuonen saddlepoint produces tighter p-values than Liu for small p-values"
    - "compute_pvalue fallback chain correctly routes through all three tiers"
    - "PythonSKATBackend null model residuals match statsmodels GLM resid_response"
    - "Eigenvalue filtering matches R threshold (mean(pos) / 100_000)"
    - "Rank-deficient genes are correctly detected and skipped"
    - "SKAT-O returns optimal rho from the 7-element grid"
    - "Python SKAT p-values match analytical results for simple test cases"
    - "PurePythonSKATTest produces valid TestResult objects via engine pattern"
  artifacts:
    - path: "tests/unit/test_davies_pvalue.py"
      provides: "Unit tests for davies.py p-value layer"
      min_lines: 100
    - path: "tests/unit/test_skat_python_backend.py"
      provides: "Unit tests for PythonSKATBackend"
      min_lines: 150
    - path: "tests/unit/test_skat_python_comparison.py"
      provides: "Validation tests comparing Python backend against analytical references"
      min_lines: 100
  key_links:
    - from: "tests/unit/test_davies_pvalue.py"
      to: "variantcentrifuge/association/backends/davies.py"
      via: "direct import of compute_pvalue, _liu_pvalue, _kuonen_pvalue"
      pattern: "from variantcentrifuge.association.backends.davies import"
    - from: "tests/unit/test_skat_python_backend.py"
      to: "variantcentrifuge/association/backends/python_backend.py"
      via: "direct import of PythonSKATBackend"
      pattern: "from variantcentrifuge.association.backends.python_backend import"
    - from: "tests/unit/test_skat_python_comparison.py"
      to: "variantcentrifuge/association/tests/skat_python.py"
      via: "import of PurePythonSKATTest for integration-style validation"
      pattern: "from variantcentrifuge.association.tests.skat_python import"
---

<objective>
Create comprehensive unit tests for the p-value layer (davies.py), PythonSKATBackend, and
PurePythonSKATTest. Validate mathematical correctness against analytical reference values
and test edge cases (rank-deficient genes, empty matrices, fallback triggering).

Purpose: These tests are the safety net ensuring the Python SKAT implementation is mathematically
correct. Without them, subtle numerical errors (wrong residual type, wrong eigenvalue driver)
could produce plausible but incorrect p-values. The tests encode the R-matching requirements
from SKAT-05 and SKAT-10.

Output: Three test files with 30+ test functions covering p-value math, backend behavior, and
end-to-end validation.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/21-pure-python-skat-backend/21-RESEARCH.md
@.planning/phases/21-pure-python-skat-backend/21-CONTEXT.md
@.planning/phases/21-pure-python-skat-backend/21-01-SUMMARY.md
@.planning/phases/21-pure-python-skat-backend/21-02-SUMMARY.md
@variantcentrifuge/association/backends/davies.py
@variantcentrifuge/association/backends/python_backend.py
@variantcentrifuge/association/tests/skat_python.py
@tests/unit/test_skat_r_backend.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: test_davies_pvalue.py — p-value layer unit tests</name>
  <files>tests/unit/test_davies_pvalue.py</files>
  <action>
Create `tests/unit/test_davies_pvalue.py` with tests for the p-value computation layer.
Mark all tests with `@pytest.mark.unit`.

**Test categories:**

1. **Liu moment-matching tests:**
   - `test_liu_single_eigenvalue`: With lambdas=[1.0], Q ~ chi2(1). Compare _liu_pvalue(q, [1.0])
     against `scipy.stats.chi2.sf(q, df=1)` for q in [1.0, 3.84, 6.63]. Should match within 1e-3
     relative (Liu is exact for single chi-squared).
   - `test_liu_equal_eigenvalues`: lambdas=[c]*k => Q ~ c*chi2(k). Compare against
     `chi2.sf(q/c, df=k)` for c=2.0, k=5, q=15.0. Should match within 1e-3.
   - `test_liu_multiple_eigenvalues`: lambdas=[5.0, 3.0, 1.0], Q=15.0. Assert 0 < p < 1
     and p is reasonable (between 0.01 and 0.5 for this case).
   - `test_liu_large_q_small_p`: lambdas=[5.0, 3.0, 1.0], Q=50.0. Assert p < 0.001.
   - `test_liu_q_at_mean`: Q = sum(lambdas) => p ~ 0.5 for symmetric-ish distribution.
   - `test_liu_empty_lambdas`: Edge case, should handle gracefully (nan or raise).

2. **Kuonen saddlepoint tests:**
   - `test_kuonen_above_mean`: lambdas=[5.0, 3.0, 1.0], Q=15.0 (above mean=9). Should return
     valid p between 0 and 1.
   - `test_kuonen_below_mean_returns_none`: Q=5.0 (below mean=9). Should return None.
   - `test_kuonen_agrees_with_liu_moderate_p`: For moderate p (0.01-0.1), Kuonen and Liu should
     agree within 20% relative.
   - `test_kuonen_tighter_than_liu_small_p`: For small p (< 1e-3), Kuonen should be closer to
     the true value than Liu (use single-eigenvalue case as ground truth).
   - `test_kuonen_single_eigenvalue`: lambdas=[1.0], should match chi2 exactly or return None.

3. **Fallback chain tests:**
   - `test_compute_pvalue_returns_tuple`: Assert return type is (float, str, bool).
   - `test_compute_pvalue_method_in_expected_set`: p_method in {"davies", "saddlepoint", "liu"}.
   - `test_compute_pvalue_liu_fallback_when_no_davies`: Set VARIANTCENTRIFUGE_NO_C_EXT=1,
     verify p_method is "saddlepoint" or "liu" (not "davies").
   - `test_compute_pvalue_empty_lambdas`: Returns (nan, "liu", False).
   - `test_compute_pvalue_reasonable_values`: For known eigenvalues and Q, p is between 0 and 1.

4. **Numerical edge cases:**
   - `test_liu_very_small_eigenvalues`: lambdas near machine epsilon. Should not crash.
   - `test_kuonen_near_singularity`: Q very close to max reachable value. Should not crash.
   - `test_compute_pvalue_deterministic`: Same input twice => same output.
  </action>
  <verify>
    Run: `pytest tests/unit/test_davies_pvalue.py -v --timeout=30` — all tests pass.
    Run: `make lint` — no lint errors in test file.
  </verify>
  <done>
    - 15+ test functions covering Liu, Kuonen, and fallback chain
    - All tests pass
    - Known analytical cases validated (single eigenvalue = chi2)
    - Edge cases handled without crashes
    - Determinism verified
  </done>
</task>

<task type="auto">
  <name>Task 2: test_skat_python_backend.py + test_skat_python_comparison.py</name>
  <files>
    tests/unit/test_skat_python_backend.py
    tests/unit/test_skat_python_comparison.py
  </files>
  <action>
**File 1: `tests/unit/test_skat_python_backend.py`** — Unit tests for PythonSKATBackend.
Mark all with `@pytest.mark.unit`.

Test categories:

1. **Environment detection:**
   - `test_detect_environment_succeeds`: detect_environment() does not raise.
   - `test_log_environment_logs_versions`: With caplog, verify numpy/scipy/statsmodels versions logged.

2. **Null model fitting:**
   - `test_fit_null_model_binary`: Binary phenotype -> NullModelResult with trait_type="binary",
     residuals in extra, sigma2=1.0.
   - `test_fit_null_model_quantitative`: Quantitative phenotype -> NullModelResult with
     trait_type="quantitative", sigma2 > 0.
   - `test_fit_null_model_with_covariates`: Covariates included -> residuals change compared
     to no covariates.
   - `test_fit_null_model_residuals_are_response`: Verify extra["residuals"] equals
     phenotype - mu_hat (not deviance or Pearson residuals).

3. **SKAT test_gene:**
   - `test_skat_basic`: 50 samples, 5 variants, binary trait. Returns dict with p_value float,
     p_method str, n_variants=5.
   - `test_skat_rank_deficient`: Genotype matrix with rank < 2 (e.g., all identical columns).
     Returns p_value=None, skip_reason="rank_deficient".
   - `test_skat_zero_variants`: Empty genotype matrix (0 columns). Returns p_value=None.
   - `test_skat_single_variant`: Matrix with 1 variant column. Rank=1 < 2, should skip.
   - `test_skat_all_zero_genotypes`: All genotype values are 0. Should handle gracefully
     (p_value=None or 1.0, not crash).
   - `test_skat_eigenvalue_driver`: Verify scipy.linalg.eigh is called with driver='evr'
     (mock or check behavior).
   - `test_skat_p_method_in_result`: Result dict contains "p_method" key with valid value.
   - `test_skat_p_converged_in_result`: Result dict contains "p_converged" key (bool).

4. **SKAT-O test_gene:**
   - `test_skato_returns_rho`: method="SKATO" -> result has rho != None, rho in [0, 1].
   - `test_skato_rho_grid`: Verify the 7 rho values are searched.
   - `test_skato_rho_zero_equals_skat`: SKAT-O at rho=0 should give same Q as pure SKAT.

5. **Burden test_gene:**
   - `test_burden_returns_pvalue`: method="Burden" -> valid p_value.
   - `test_burden_analytical_p_method`: p_method should be "analytical".

6. **Cleanup:**
   - `test_cleanup_noop`: cleanup() does not raise.

**File 2: `tests/unit/test_skat_python_comparison.py`** — Validation tests comparing Python
backend against analytical reference values. Mark with `@pytest.mark.unit`.

Test categories:

1. **Deterministic seed fixtures**: Use `np.random.default_rng(seed)` for reproducibility.
   Create a parametrized fixture generating 10+ synthetic genes with varying:
   - n_samples: 50, 100, 200
   - n_variants: 3, 5, 10, 20
   - case_fraction: 0.3, 0.5
   - effect_size: 0 (null), 0.5 (moderate)

2. **Self-consistency tests:**
   - `test_null_phenotype_uniform_p`: Under null (random phenotype, no true association),
     p-values should be roughly uniform. Run 50 genes with random phenotypes, verify
     mean(p) is between 0.2 and 0.8 (not systematically biased).
   - `test_strong_signal_small_p`: Under strong signal (cases have many alt alleles,
     controls have few), p-value should be small (< 0.05).
   - `test_skat_skato_consistency`: For same data, SKAT-O p should be <= min(SKAT p, Burden p)
     (omnibus is at least as powerful as individual tests).

3. **Known-value tests:**
   - `test_single_eigenvalue_chi2_exact`: With a single eigenvalue lambda, Q ~ lambda*chi2(1).
     Verify p matches chi2.sf(Q/lambda, 1) within 1e-4 relative.
   - `test_equal_eigenvalues_chi2_exact`: With k equal eigenvalues c, Q ~ c*chi2(k).
     Verify p matches chi2.sf(Q/c, k) within 1e-4 relative.

4. **Regression tests (golden values):**
   - `test_golden_fixture_50_samples`: Fixed seed, 50 samples, 5 variants, known expected
     p-value range. Pin the exact p-value after first successful run as a regression guard.
     Use `pytest.approx(expected, rel=1e-6)`.

5. **PurePythonSKATTest integration:**
   - `test_pure_python_skat_test_run`: Create PurePythonSKATTest, call check_dependencies(),
     prepare(), run() with synthetic contingency_data, finalize(). Verify TestResult is valid.
   - `test_pure_python_skat_test_extra_keys`: Verify extra dict contains expected keys
     (skat_p_method, skat_p_converged, skat_method).
   - `test_pure_python_skat_test_skip_reason`: Rank-deficient gene -> extra contains skip_reason.

Use `@pytest.fixture` for shared backend/null model setup to avoid redundant GLM fits.
Use `@pytest.mark.parametrize` for multi-gene validation sweeps.
  </action>
  <verify>
    Run: `pytest tests/unit/test_skat_python_backend.py tests/unit/test_skat_python_comparison.py -v --timeout=60` — all tests pass.
    Run: `pytest tests/unit/test_davies_pvalue.py tests/unit/test_skat_python_backend.py tests/unit/test_skat_python_comparison.py -v --timeout=60` — full suite passes.
    Run: `make lint` — no lint errors.
    Run: `pytest -m unit -x -q --timeout=120 2>&1 | tail -5` — ALL unit tests pass (no regressions).
  </verify>
  <done>
    - test_skat_python_backend.py has 15+ tests covering all backend methods
    - test_skat_python_comparison.py has 10+ validation tests with analytical references
    - All tests pass deterministically (seeded RNG)
    - Null-phenotype p-values are not systematically biased
    - Strong-signal p-values are appropriately small
    - Edge cases (rank-deficient, empty, all-zero) handled correctly
    - PurePythonSKATTest integration verified
    - No regressions in existing test suite
  </done>
</task>

</tasks>

<verification>
1. `pytest tests/unit/test_davies_pvalue.py -v` — all pass
2. `pytest tests/unit/test_skat_python_backend.py -v` — all pass
3. `pytest tests/unit/test_skat_python_comparison.py -v` — all pass
4. `pytest -m unit -x -q` — full unit suite passes, no regressions
5. `make lint` — clean
6. Total new tests: 30+
</verification>

<success_criteria>
- Liu validated against chi-squared ground truth (single and equal eigenvalues)
- Kuonen validated as tighter than Liu for small p-values
- Fallback chain tested with Davies disabled (env var)
- PythonSKATBackend tested for SKAT, Burden, and SKAT-O methods
- Rank-deficient and edge cases covered
- Self-consistency: null phenotypes give uniform p, strong signals give small p
- PurePythonSKATTest run() produces valid TestResult
- All existing tests still pass
</success_criteria>

<output>
After completion, create `.planning/phases/21-pure-python-skat-backend/21-03-SUMMARY.md`
</output>
