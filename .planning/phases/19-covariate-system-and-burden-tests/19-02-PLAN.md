---
phase: 19-covariate-system-burden-tests
plan: 02
type: execute
wave: 2
depends_on: ["19-01"]
files_modified:
  - variantcentrifuge/association/tests/logistic_burden.py
  - variantcentrifuge/association/tests/linear_burden.py
  - variantcentrifuge/association/tests/__init__.py
  - variantcentrifuge/association/engine.py
  - variantcentrifuge/association/__init__.py
  - variantcentrifuge/stages/analysis_stages.py
  - variantcentrifuge/cli.py
autonomous: true

must_haves:
  truths:
    - "Logistic burden test reports OR + 95% CI for binary trait with covariates, matching statsmodels.Logit"
    - "Linear burden test reports beta + SE for quantitative trait, matching statsmodels.OLS"
    - "Firth fallback activates on separation and reports Firth p-value or NA + warning code"
    - "Genes with zero carriers appear in output with p_value=None and warning code, never omitted"
    - "CLI --covariate-file, --covariates, --trait-type, --variant-weights args work end-to-end"
    - "Engine builds per-gene genotype matrix and passes it in contingency_data for regression tests"
    - "Fisher test still works unchanged when regression keys absent from contingency_data"
  artifacts:
    - path: "variantcentrifuge/association/tests/logistic_burden.py"
      provides: "LogisticBurdenTest with Firth fallback and warning codes"
      exports: ["LogisticBurdenTest"]
    - path: "variantcentrifuge/association/tests/linear_burden.py"
      provides: "LinearBurdenTest with beta + SE output"
      exports: ["LinearBurdenTest"]
    - path: "variantcentrifuge/cli.py"
      provides: "New CLI args for covariate/trait/weight configuration"
      contains: "covariate-file"
    - path: "variantcentrifuge/stages/analysis_stages.py"
      provides: "Covariate loading and genotype matrix building in AssociationAnalysisStage"
      contains: "load_covariates"
  key_links:
    - from: "variantcentrifuge/association/engine.py"
      to: "variantcentrifuge/association/tests/logistic_burden.py"
      via: "_build_registry adds logistic_burden and linear_burden"
      pattern: "logistic_burden.*LogisticBurdenTest"
    - from: "variantcentrifuge/stages/analysis_stages.py"
      to: "variantcentrifuge/association/genotype_matrix.py"
      via: "build_genotype_matrix called per gene in _process"
      pattern: "build_genotype_matrix"
    - from: "variantcentrifuge/stages/analysis_stages.py"
      to: "variantcentrifuge/association/covariates.py"
      via: "load_covariates called once in _process when covariate_file set"
      pattern: "load_covariates"
    - from: "variantcentrifuge/cli.py"
      to: "variantcentrifuge/association/base.py"
      via: "CLI args populate AssociationConfig fields"
      pattern: "covariate_file|trait_type|variant_weights"
---

<objective>
Implement LogisticBurdenTest and LinearBurdenTest as AssociationTest subclasses, wire genotype matrix building and covariate loading into AssociationAnalysisStage, register new tests in the engine, and add CLI arguments.

Purpose: This is the core execution plan — after this, users can run `--perform-association --association-tests logistic_burden --covariate-file cov.tsv --trait-type binary` and get regression-based burden test results with effect sizes, confidence intervals, and convergence warnings.

Output: Two new test modules, updated engine registry, updated stage with genotype matrix + covariate integration, and new CLI arguments.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/19-covariate-system-and-burden-tests/19-CONTEXT.md
@.planning/phases/19-covariate-system-and-burden-tests/19-RESEARCH.md
@.planning/phases/19-covariate-system-and-burden-tests/19-01-SUMMARY.md
@variantcentrifuge/association/base.py
@variantcentrifuge/association/engine.py
@variantcentrifuge/association/tests/__init__.py
@variantcentrifuge/association/tests/fisher.py
@variantcentrifuge/association/covariates.py
@variantcentrifuge/association/genotype_matrix.py
@variantcentrifuge/association/weights.py
@variantcentrifuge/stages/analysis_stages.py (AssociationAnalysisStage section)
@variantcentrifuge/cli.py (association args section ~lines 408-425, config mapping ~lines 1034-1040, validation ~lines 1174-1177)
@variantcentrifuge/gene_burden.py (for _find_gt_columns and aggregation functions — reuse pattern)
</context>

<tasks>

<task type="auto">
  <name>Task 1: Implement LogisticBurdenTest and LinearBurdenTest</name>
  <files>
    variantcentrifuge/association/tests/logistic_burden.py
    variantcentrifuge/association/tests/linear_burden.py
    variantcentrifuge/association/tests/__init__.py
    variantcentrifuge/association/engine.py
    variantcentrifuge/association/__init__.py
  </files>
  <action>
**1a. Create logistic_burden.py** — `LogisticBurdenTest(AssociationTest)`:
- `name` property returns `"logistic_burden"`
- `check_dependencies()` does lazy `import statsmodels.api` and raises ImportError if missing
- `run(gene, contingency_data, config) -> TestResult`:
  1. Extract from contingency_data: `genotype_matrix` (ndarray), `variant_mafs` (ndarray), `phenotype_vector` (ndarray), `covariate_matrix` (ndarray | None). If `genotype_matrix` not present, return TestResult with p_value=None and extra={"warnings": ["NO_GENOTYPE_MATRIX"]}
  2. Call `get_weights(variant_mafs, config.variant_weights)` to get weight vector
  3. Compute weighted burden score: `burden = genotype_matrix @ weights` (shape: n_samples)
  4. Build design matrix: `X = sm.add_constant(burden.reshape(-1, 1))`. If covariate_matrix is not None and has columns, `X = np.column_stack([X, covariate_matrix])`
  5. Compute carrier stats: n_carriers, n_carriers_cases, n_carriers_controls from burden > 0 and phenotype
  6. Pre-flight separation checks: PERFECT_SEPARATION (all carriers same phenotype), QUASI_SEPARATION (>=90%), ZERO_CARRIERS_ONE_GROUP
  7. LOW_CARRIER_COUNT warning if total carriers < 3
  8. Fit `sm.Logit(phenotype, X).fit(disp=False, maxiter=100)` inside `warnings.catch_warnings(record=True)`
  9. Check convergence: `result.mle_retvals.get("converged", True)` AND `result.bse.max() > 100.0` (Pitfall 2 from RESEARCH.md)
  10. If not converged or BSE too large: attempt Firth fallback via `_firth_logistic(phenotype, X, max_iter=config.firth_max_iter)`. If Firth returns result, use it. If Firth returns None, return NA result with FIRTH_CONVERGE_FAIL warning.
  11. Extract from result (index 1, not 0 — Pitfall 6): `beta = params[1]`, `se = bse[1]`, `p_value = pvalues[1]`, `ci = conf_int()` (ndarray, not DataFrame — Pitfall 1), `ci_lower = ci[1, 0]`, `ci_upper = ci[1, 1]`
  12. Compute `odds_ratio = exp(beta)`, `or_ci_lower = exp(ci_lower)`, `or_ci_upper = exp(ci_upper)`
  13. Return TestResult with: effect_size=odds_ratio, ci_lower=or_ci_lower, ci_upper=or_ci_upper, extra={"beta": beta, "se": se, "n_carriers": n_carriers, "n_carriers_cases": n_carriers_cases, "n_carriers_controls": n_carriers_controls, "warnings": warning_codes}

- Include `_firth_logistic(y, X, max_iter, tol)` as a private function (the ~80 line Newton-Raphson implementation from RESEARCH.md Pattern 5). Also include `_firth_loglik(beta, y, X)` helper.

- CRITICAL: Never report a non-converged p-value without warning flag. Never silently omit genes — always return a TestResult row (with p_value=None + warning if needed).

**1b. Create linear_burden.py** — `LinearBurdenTest(AssociationTest)`:
- `name` property returns `"linear_burden"`
- `check_dependencies()` lazily imports statsmodels
- `run(gene, contingency_data, config) -> TestResult`:
  1. Extract genotype_matrix, variant_mafs, phenotype_vector, covariate_matrix. If missing, return p_value=None TestResult.
  2. Get weights via `get_weights(variant_mafs, config.variant_weights)`
  3. Compute burden, build design matrix (same pattern as logistic but no Firth)
  4. Fit `sm.OLS(phenotype, X).fit()`
  5. Extract beta, se, p_value, ci from index 1 (after intercept). `ci = result.conf_int()` returns ndarray.
  6. Return TestResult with: effect_size=beta (not OR for linear), ci_lower=ci[1,0], ci_upper=ci[1,1], extra={"se": se, "n_carriers": n_carriers, "warnings": []}

**1c. Update tests/__init__.py** — add lazy loading for LogisticBurdenTest and LinearBurdenTest in the `__getattr__` function. Update `__all__`.

**1d. Update engine.py** — add to `_build_registry()`:
```python
from variantcentrifuge.association.tests.logistic_burden import LogisticBurdenTest
from variantcentrifuge.association.tests.linear_burden import LinearBurdenTest
```
Register as `"logistic_burden": LogisticBurdenTest, "linear_burden": LinearBurdenTest`.

**1e. Update association/__init__.py** — no changes needed unless you want to export new classes (not required for registry-based loading).

**Output column naming:** The engine currently uses `{test_name}_or` for effect size. For linear_burden, the effect size IS beta (not OR). The engine's generic column naming handles this — `linear_burden_or` will contain beta. This is acceptable for Phase 19; Phase 22 will standardize column naming.
  </action>
  <verify>
Run: `python -c "
from variantcentrifuge.association.engine import _build_registry
reg = _build_registry()
print('Registry:', sorted(reg.keys()))
assert 'logistic_burden' in reg
assert 'linear_burden' in reg
assert 'fisher' in reg
print('Registry test passed')
"`

Run: `python -c "
from variantcentrifuge.association.tests.logistic_burden import LogisticBurdenTest
from variantcentrifuge.association.tests.linear_burden import LinearBurdenTest
t = LogisticBurdenTest()
print(t.name)
t2 = LinearBurdenTest()
print(t2.name)
"`

Run: `make lint`
  </verify>
  <done>
- LogisticBurdenTest runs statsmodels Logit with Firth fallback, reports OR + CI + warning codes
- LinearBurdenTest runs statsmodels OLS, reports beta + SE + CI
- Both registered in engine registry alongside Fisher
- Both handle missing genotype_matrix gracefully (p_value=None)
- Firth implementation is self-contained (~80 lines, no external dependency)
  </done>
</task>

<task type="auto">
  <name>Task 2: Wire covariate loading and genotype matrix into AssociationAnalysisStage + CLI args</name>
  <files>
    variantcentrifuge/stages/analysis_stages.py
    variantcentrifuge/cli.py
  </files>
  <action>
**2a. Update cli.py** — add new CLI arguments in the "Association Analysis" group (after existing --skat-backend):

```python
stats_group.add_argument(
    "--covariate-file",
    type=str,
    default=None,
    help="Path to covariate file (TSV/CSV). First column = sample ID, remaining = covariates.",
)
stats_group.add_argument(
    "--covariates",
    type=str,
    default=None,
    help="Comma-separated covariate column names to use (default: all columns in file)",
)
stats_group.add_argument(
    "--categorical-covariates",
    type=str,
    default=None,
    help="Comma-separated column names to force-treat as categorical (default: auto-detect)",
)
stats_group.add_argument(
    "--trait-type",
    choices=["binary", "quantitative"],
    default="binary",
    help="Trait type for burden tests (default: binary)",
)
stats_group.add_argument(
    "--variant-weights",
    type=str,
    default="beta:1,25",
    help="Variant weighting scheme: 'beta:a,b' or 'uniform' (default: beta:1,25)",
)
```

Update the config mapping section (~line 1034) to pass these to cfg:
```python
cfg["covariate_file"] = getattr(args, "covariate_file", None)
cfg["covariate_columns"] = [c.strip() for c in args.covariates.split(",")] if getattr(args, "covariates", None) else None
cfg["categorical_covariates"] = [c.strip() for c in args.categorical_covariates.split(",")] if getattr(args, "categorical_covariates", None) else None
cfg["trait_type"] = getattr(args, "trait_type", "binary")
cfg["variant_weights"] = getattr(args, "variant_weights", "beta:1,25")
```

Update --association-tests help text to include new tests:
```
help="Comma-separated list of association tests to run (default: fisher). Available: fisher, logistic_burden, linear_burden"
```

Add validation: if `--covariate-file` is set but `--perform-association` is not, call `parser.error()`. If `--trait-type quantitative` and any test is `logistic_burden`, call `parser.error()` (logistic is binary only).

**2b. Update AssociationAnalysisStage._process() in analysis_stages.py** — after building AssociationConfig, before running engine:

1. Pass new config fields to AssociationConfig constructor:
```python
assoc_config = AssociationConfig(
    # ... existing fields ...
    covariate_file=context.config.get("covariate_file"),
    covariate_columns=context.config.get("covariate_columns"),
    categorical_covariates=context.config.get("categorical_covariates"),
    trait_type=context.config.get("trait_type", "binary"),
    variant_weights=context.config.get("variant_weights", "beta:1,25"),
)
```

2. Log trait type confirmation: `logger.info(f"Association analysis: trait type = {assoc_config.trait_type}")`

3. **Tiered sample size warnings** (from CONTEXT.md):
   - Cases < 10: `logger.error(...)` and return context (refuse to run)
   - Cases < 50: `logger.warning("Fewer than 50 cases — no practical power for regression tests")`
   - Cases < 200: `logger.warning("Fewer than 200 cases — underpowered for SKAT")`
   - Case:control ratio > 1:20: `logger.warning("Case:control ratio exceeds 1:20 — Type I error inflation risk")`

4. **Load covariates once** (if covariate_file set):
```python
covariate_matrix = None
if assoc_config.covariate_file:
    from variantcentrifuge.association.covariates import load_covariates
    covariate_matrix, cov_names = load_covariates(
        assoc_config.covariate_file,
        list(context.vcf_samples),
        assoc_config.covariate_columns,
        assoc_config.categorical_covariates,
    )
    logger.info(f"Loaded {covariate_matrix.shape[1]} covariates: {cov_names}")
```

5. **Build phenotype vector once:**
```python
phenotype_vector = None
if context.vcf_samples:
    import numpy as np
    vcf_list = list(context.vcf_samples)
    case_set_all = set(case_samples)
    phenotype_vector = np.array([1 if s in case_set_all else 0 for s in vcf_list], dtype=float)
    logger.info(f"Phenotype vector: {int(phenotype_vector.sum())} cases, {int((1 - phenotype_vector).sum())} controls")
```

6. **Determine if regression tests are requested:**
```python
needs_genotype_matrix = any(
    t in test_names for t in ("logistic_burden", "linear_burden", "skat", "skat_python")
)
```

7. **Modify the per-gene loop** to build genotype matrix when needed. The current code builds `gene_burden_data` as a list of dicts. Add a new loop (or modify existing) that, for genes needing regression, builds the genotype matrix and adds regression keys to contingency_data BEFORE passing to engine.

The approach: after building `gene_burden_data` via existing aggregation, if `needs_genotype_matrix`, iterate genes again and augment each gene's dict with:
```python
if needs_genotype_matrix and gt_columns and vcf_samples_list:
    from variantcentrifuge.association.genotype_matrix import build_genotype_matrix
    for gene_data in gene_burden_data:
        gene_name = gene_data["GENE"]
        gene_df = df[df["GENE"] == gene_name]
        G, mafs, sample_mask, gt_warnings = build_genotype_matrix(
            gene_df, vcf_samples_list, gt_columns,
            is_binary=(assoc_config.trait_type == "binary"),
            phenotype_vector=phenotype_vector,
        )
        for w in gt_warnings:
            logger.warning(f"Gene {gene_name}: {w}")
        # Apply sample mask to phenotype and covariates
        if not all(sample_mask):
            pv = phenotype_vector[sample_mask] if phenotype_vector is not None else None
            cm = covariate_matrix[sample_mask] if covariate_matrix is not None else None
        else:
            pv = phenotype_vector
            cm = covariate_matrix
        gene_data["genotype_matrix"] = G
        gene_data["variant_mafs"] = mafs
        gene_data["phenotype_vector"] = pv
        gene_data["covariate_matrix"] = cm
        gene_data["vcf_samples"] = vcf_samples_list
```

This augmentation is backward compatible: Fisher ignores the new keys. Memory is bounded because matrices are small per-gene (200 samples x 10 variants = 16KB).

8. **Per-gene MAC check:** After building genotype matrix, if sum of burden scores (or total minor allele count) < 5, set `gene_data["skip_regression"] = True` and add to warnings. The burden test implementations should check this and return NA + warning.

IMPORTANT: Keep all existing aggregation paths (column-based, GT-based, legacy) unchanged. The genotype matrix building is an additional step for regression tests only.
  </action>
  <verify>
Run: `python -c "from variantcentrifuge.cli import build_parser; p = build_parser(); args = p.parse_args(['--perform-association', '--association-tests', 'logistic_burden', '--covariate-file', '/tmp/test.tsv', '--trait-type', 'binary', '--variant-weights', 'beta:1,25']); print(args.covariate_file, args.trait_type, args.variant_weights)"` — verifying CLI args parse correctly. (Note: build_parser may not exist as a standalone function; adapt to actual CLI structure.)

Run: `make lint` to check for style issues in modified files.

Run: `pytest tests/unit/test_association_stage.py tests/unit/test_association_engine.py tests/unit/test_association_fisher.py -x` — existing tests must still pass.
  </verify>
  <done>
- CLI args --covariate-file, --covariates, --categorical-covariates, --trait-type, --variant-weights all parseable
- AssociationAnalysisStage loads covariates once, builds phenotype vector once
- Per-gene genotype matrix built only when regression tests are requested
- Genotype matrix + covariates + phenotype passed via contingency_data (backward compatible)
- Tiered sample size warnings implemented
- Existing Fisher-only path unchanged
- All existing tests pass
  </done>
</task>

</tasks>

<verification>
- `make lint` passes
- `pytest tests/unit/test_association_base.py tests/unit/test_association_engine.py tests/unit/test_association_fisher.py tests/unit/test_association_stage.py -x` — all existing tests pass
- `python -c "from variantcentrifuge.association.engine import _build_registry; r = _build_registry(); assert len(r) == 3"` — three tests registered
- The engine can be constructed with `AssociationEngine.from_names(["fisher", "logistic_burden"], AssociationConfig())` without error
</verification>

<success_criteria>
1. LogisticBurdenTest with Firth fallback fully implemented
2. LinearBurdenTest fully implemented
3. Both registered in engine and constructable via from_names()
4. CLI args parse and map to config correctly
5. AssociationAnalysisStage builds genotype matrices for regression tests
6. Covariates loaded once, phenotype vector built once
7. All existing tests pass (no regressions)
</success_criteria>

<output>
After completion, create `.planning/phases/19-covariate-system-and-burden-tests/19-02-SUMMARY.md`
</output>
