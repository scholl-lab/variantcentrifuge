---
phase: 24-pure-python-coast-backend
plan: 03
type: execute
wave: 3
depends_on: ["24-01", "24-02"]
files_modified:
  - scripts/generate_coast_golden.R
  - tests/fixtures/coast_golden/README.md
  - tests/unit/test_coast_python.py
  - tests/unit/test_coast_python_comparison.py
autonomous: true

must_haves:
  truths:
    - "R script generates golden reference p-values for COAST using AllelicSeries::COAST()"
    - "Golden file test compares Python COAST output against R reference with tiered tolerance"
    - "Unit tests verify each burden model (baseline/sum/max x count/indicator) independently"
    - "Unit tests verify allelic SKAT component with annotation-aware weights"
    - "Integration tests verify PurePythonCOASTTest lifecycle (check_deps -> prepare -> run -> finalize)"
    - "All existing tests pass (Fisher, burden, SKAT, ACAT-O, COAST classify_variants)"
  artifacts:
    - path: "scripts/generate_coast_golden.R"
      provides: "R script generating golden reference files for offline validation"
      min_lines: 80
    - path: "tests/unit/test_coast_python.py"
      provides: "Unit tests for PythonCOASTBackend components and PurePythonCOASTTest lifecycle"
      min_lines: 200
    - path: "tests/unit/test_coast_python_comparison.py"
      provides: "Validation tests comparing Python COAST against R golden reference values"
      min_lines: 100
  key_links:
    - from: "tests/unit/test_coast_python_comparison.py"
      to: "variantcentrifuge/association/backends/coast_python.py"
      via: "Imports PythonCOASTBackend and compares output against hardcoded R reference values"
      pattern: "PythonCOASTBackend"
    - from: "tests/unit/test_coast_python.py"
      to: "variantcentrifuge/association/tests/allelic_series_python.py"
      via: "Tests PurePythonCOASTTest lifecycle and run()"
      pattern: "PurePythonCOASTTest"
    - from: "scripts/generate_coast_golden.R"
      to: "tests/unit/test_coast_python_comparison.py"
      via: "R script outputs golden values that are hardcoded as constants in Python test"
      pattern: "COAST"
---

<objective>
Create R golden file generation script and comprehensive test suite validating the Python COAST backend against R AllelicSeries::COAST() reference values and independent mathematical checks.

Purpose: Prove correctness of the Python implementation within tiered tolerance of R, following the exact pattern used for SKAT validation in Phase 21.
Output: R script for golden file generation, unit tests for backend math, comparison tests against R reference values.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/24-pure-python-coast-backend/24-RESEARCH.md
@.planning/phases/24-pure-python-coast-backend/24-01-SUMMARY.md
@.planning/phases/24-pure-python-coast-backend/24-02-SUMMARY.md

# Pattern to follow:
@tests/unit/test_skat_python_comparison.py
@tests/unit/test_coast.py

# Implementation to test:
@variantcentrifuge/association/backends/coast_python.py
@variantcentrifuge/association/tests/allelic_series_python.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: R golden file generation script</name>
  <files>scripts/generate_coast_golden.R, tests/fixtures/coast_golden/README.md</files>
  <action>
Create `scripts/generate_coast_golden.R` — an R script that runs AllelicSeries::COAST() on deterministic synthetic data and prints golden reference values that will be hardcoded into the Python comparison test.

The script must be runnable offline by anyone with R + AllelicSeries installed:
```
Rscript scripts/generate_coast_golden.R
```

**Scenarios to generate (matching the user's explicit requirements):**

1. **Binary trait, null phenotype** (seed=42, n=100, k=9 variants: 3 BMV + 3 DMV + 3 PTV)
   - No signal — omnibus p should be large
2. **Binary trait, with signal** (seed=123, n=100, k=9, cases enriched for alt alleles in PTV)
   - Moderate signal — omnibus p should be small
3. **Quantitative trait** (seed=77, n=100, k=9)
   - Standard normal phenotype, no signal
4. **Unequal category sizes** (seed=200, n=100, k=12: 2 BMV + 4 DMV + 6 PTV)
   - Tests robustness to unequal variant counts
5. **Single variant per category** (seed=300, n=100, k=3: 1 BMV + 1 DMV + 1 PTV)
   - Edge case: minimum viable COAST input

For each scenario, the R script should:

```r
library(AllelicSeries)

# Generate deterministic synthetic data
set.seed(SEED)
n <- N
geno <- matrix(sample(0:2, n*k, replace=TRUE, prob=c(0.6, 0.3, 0.1)), nrow=n, ncol=k)
anno <- c(rep(1, n_bmv), rep(2, n_dmv), rep(3, n_ptv))  # annotation codes

# Phenotype
if (binary) {
  pheno <- sample(0:1, n, replace=TRUE)
  if (signal) {
    # Enrich cases for alt alleles in PTV variants
    case_idx <- which(pheno == 1)
    for (j in ptv_cols) {
      geno[case_idx, j] <- pmin(geno[case_idx, j] + rbinom(length(case_idx), 1, 0.5), 2)
    }
  }
} else {
  pheno <- rnorm(n)
}

# Run COAST
result <- COAST(
  anno = anno,
  geno = geno,
  pheno = pheno,
  covar = NULL,
  weights = c(1, 2, 3),
  is_pheno_binary = binary
)

# Extract ALL p-values from Pvals slot
pvals <- result@Pvals
cat(sprintf("Scenario: %s\n", scenario_name))
cat(sprintf("  Seed: %d, n: %d, k: %d\n", SEED, n, k))
for (name in names(pvals)) {
  cat(sprintf("  %s: %.15e\n", name, pvals[name]))
}
cat("\n")
```

Also print the raw genotype matrix and phenotype for the first scenario so the Python test can reconstruct the exact same data.

**Output format:** The script prints structured output that can be copy-pasted into the Python test file as constants. Include a header comment explaining how to re-run.

Create `tests/fixtures/coast_golden/README.md` (short, 10 lines):
```
# COAST Golden Reference Values

Generated by: `Rscript scripts/generate_coast_golden.R`
Requires: R with AllelicSeries package installed
Used by: tests/unit/test_coast_python_comparison.py

These are pre-computed R reference values hardcoded in the Python test file.
Re-run the R script if the AllelicSeries package version changes.
```

**IMPORTANT:** The R script is for offline execution by the user. It will NOT be run in CI. The golden values it produces will be hardcoded as constants in the Python test file (next task). The user has explicitly requested this approach, matching the SKAT Phase 21 pattern.
  </action>
  <verify>
File `scripts/generate_coast_golden.R` exists and has valid R syntax.
File `tests/fixtures/coast_golden/README.md` exists.
  </verify>
  <done>
R script generates golden reference p-values for 5 COAST scenarios using deterministic synthetic data. Output format is suitable for hardcoding into Python test constants.
  </done>
</task>

<task type="auto">
  <name>Task 2: Python COAST unit tests and R reference comparison tests</name>
  <files>tests/unit/test_coast_python.py, tests/unit/test_coast_python_comparison.py</files>
  <action>
Create TWO test files following the test_skat_python_comparison.py pattern:

**File 1: `tests/unit/test_coast_python.py`** — Unit tests for PythonCOASTBackend components and PurePythonCOASTTest lifecycle.

Classes and tests:

```python
@pytest.mark.unit
@pytest.mark.coast
class TestCOASTBurdenAggregation:
    """Test _aggregate_by_category() for count/indicator, none/sum/max methods."""

    def test_count_none_returns_3_columns():
        # 6 variants: 2 BMV + 2 DMV + 2 PTV, verify shape (n, 3)
        # Verify per-category sums match manual computation

    def test_indicator_converts_to_binary():
        # Same setup but indicator=True; verify 0/1 values

    def test_sum_method_returns_weighted_sum():
        # weights=[1,2,3]; verify sum_count = 1*N_bmv + 2*N_dmv + 3*N_ptv per sample

    def test_max_method_returns_max_weighted_value():
        # weights=[1,2,3]; verify max_count = max(1*N_bmv, 2*N_dmv, 3*N_ptv) per sample

    def test_empty_category_yields_zero_column():
        # All variants in one category; other columns should be zero


@pytest.mark.unit
@pytest.mark.coast
class TestCOASTBurdenTests:
    """Test _run_burden_test() for quantitative and binary traits."""

    def test_quantitative_1df_returns_valid_p():
        # Simple OLS with 1 predictor column; verify 0 < p < 1

    def test_quantitative_3df_returns_valid_p():
        # OLS with 3 predictor columns (baseline); verify 0 < p < 1

    def test_binary_1df_lrt_returns_valid_p():
        # Logit LRT with 1 predictor; verify 0 < p < 1

    def test_binary_3df_lrt_returns_valid_p():
        # Logit LRT with 3 predictors (baseline); verify 0 < p < 1

    def test_strong_signal_gives_small_p():
        # Predictor perfectly correlated with phenotype; p < 0.05

    def test_null_predictor_gives_large_p():
        # Random predictor uncorrelated with phenotype; mean p over 20 trials in [0.2, 0.8]


@pytest.mark.unit
@pytest.mark.coast
class TestCOASTAllelicSKATWeights:
    """Test _compute_allelic_skat_weights() and allelic SKAT component."""

    def test_weights_use_aaf_not_2aaf():
        # Verify w_j = sqrt(w_anno / (aaf*(1-aaf))) not sqrt(w_anno / (2*aaf*(1-aaf)))
        # Check against manual computation

    def test_monomorphic_variant_clamped():
        # Variant with aaf=0 should be clamped to 1e-8; no div-by-zero

    def test_skat_returns_valid_p():
        # Run allelic SKAT with known weights; verify 0 < p <= 1


@pytest.mark.unit
@pytest.mark.coast
class TestCOASTOmnibus:
    """Test full test_gene() pipeline: 6 burden + 1 SKAT + Cauchy combination."""

    def test_omnibus_returns_valid_p():
        # Build synthetic gene data with all 3 categories; verify p in (0, 1]

    def test_cauchy_weights_are_1_1_1_1_1_1_6():
        # Verify Cauchy weights by checking that test_gene returns consistent results

    def test_deterministic_across_calls():
        # Same input twice -> same output

    def test_null_phenotype_moderate_p():
        # No signal -> mean omnibus p over 20 null genes in [0.2, 0.8]


@pytest.mark.unit
@pytest.mark.coast
class TestPurePythonCOASTTestLifecycle:
    """Integration tests for PurePythonCOASTTest following PurePythonSKATTest pattern."""

    def test_full_lifecycle():
        # check_dependencies -> prepare -> run -> finalize
        # Verify TestResult fields

    def test_parallel_safe_is_true():
        assert PurePythonCOASTTest.parallel_safe is True

    def test_name_is_coast():
        assert PurePythonCOASTTest().name == "coast"

    def test_effect_column_names_all_none():
        # All four keys present, all values None

    def test_no_genotype_matrix_returns_none():
        # Missing genotype_matrix -> p_value=None, skip_reason

    def test_missing_categories_returns_none():
        # Only PTV variants -> p_value=None with skip_reason

    def test_extra_keys_match_coast_test():
        # coast_burden_p_value, coast_skat_p_value, coast_n_bmv, coast_n_dmv, coast_n_ptv

    def test_engine_registration_swap():
        # With coast_backend="python", engine.from_names(["coast"], config) returns PurePythonCOASTTest
        from variantcentrifuge.association.engine import _build_registry
        from variantcentrifuge.association.base import AssociationConfig
        # Verify the swap mechanism works

    def test_multiple_genes_sequential():
        # Process 3 genes sequentially; null model reused
```

For building contingency_data in these tests, use this helper (similar to test_coast.py):

```python
def _make_coast_contingency_data(n_samples=100, seed=42):
    rng = np.random.default_rng(seed)
    # 9 variants: 3 BMV + 3 DMV + 3 PTV
    geno = rng.choice([0, 1, 2], size=(n_samples, 9), p=[0.6, 0.3, 0.1]).astype(np.float64)
    phenotype = rng.integers(0, 2, n_samples).astype(np.float64)
    gene_df = _make_gene_df(...)  # with proper EFFECT/IMPACT/SIFT/PolyPhen for 3+3+3
    return {
        "genotype_matrix": geno,
        "phenotype_vector": phenotype,
        "gene_df": gene_df,
        "proband_count": int(phenotype.sum()),
        "control_count": int((1-phenotype).sum()),
        "n_qualifying_variants": 9,
        "covariate_matrix": None,
    }
```

**File 2: `tests/unit/test_coast_python_comparison.py`** — Validation against R golden reference values.

Follow the EXACT pattern of `test_skat_python_comparison.py`:

```python
"""
Validation tests comparing Python COAST backend against R AllelicSeries::COAST() reference values.

R reference values were derived offline using:
    library(AllelicSeries)
    set.seed(SEED)
    ... (see scripts/generate_coast_golden.R)

Tolerance tiers:
  - For p > 1e-4: relative tolerance < 1e-4 (matching SKAT standard)
  - For p <= 1e-4: log10 tolerance < 0.5

Covers requirements: COAST-PY-01
"""

# Pre-computed R reference constants
# These will be populated after running scripts/generate_coast_golden.R
# For now, use placeholder values and mark tests as needing golden update

_SCENARIO_1_SEED = 42
_SCENARIO_1_N = 100
_SCENARIO_1_K = 9  # 3 BMV + 3 DMV + 3 PTV
_SCENARIO_1_TRAIT = "binary"
_SCENARIO_1_SIGNAL = False

# Golden values from R (PLACEHOLDER - update after running R script)
# Format: {"base_count": p, "base_ind": p, "sum_count": p, "sum_ind": p,
#           "max_count": p, "max_ind": p, "allelic_skat": p, "omni": p}


@pytest.mark.unit
@pytest.mark.coast
class TestCOASTRReferenceValidation:
    """
    Validates Python COAST backend output against pre-computed R reference values.

    These values MUST be generated by running scripts/generate_coast_golden.R
    and hardcoding the output here. Until that is done, tests use self-consistency
    checks (Python determinism) rather than R comparison.
    """

    def _make_scenario_data(self, seed, n, k_per_cat, trait_type, signal=False):
        """Generate synthetic data matching the R script's data generation."""
        rng = np.random.default_rng(seed)
        k = k_per_cat * 3
        geno = rng.choice([0, 1, 2], size=(n, k), p=[0.6, 0.3, 0.1]).astype(np.float64)
        anno_codes = np.array([1]*k_per_cat + [2]*k_per_cat + [3]*k_per_cat)

        if trait_type == "binary":
            phenotype = rng.integers(0, 2, n).astype(np.float64)
            if signal:
                case_idx = np.where(phenotype == 1)[0]
                ptv_cols = range(2*k_per_cat, k)
                for j in ptv_cols:
                    geno[case_idx, j] = np.minimum(
                        geno[case_idx, j] + rng.binomial(1, 0.5, len(case_idx)).astype(float), 2.0
                    )
        else:
            phenotype = rng.standard_normal(n)

        return geno, anno_codes, phenotype

    def test_scenario_1_binary_null_deterministic(self):
        """Scenario 1 (binary null): Python output is deterministic across calls."""
        # Run twice, verify identical results

    def test_scenario_1_binary_null_p_in_range(self):
        """Scenario 1 (binary null): omnibus p in [0.05, 1.0] (no signal expected)."""

    def test_scenario_2_binary_signal_small_p(self):
        """Scenario 2 (binary with signal): omnibus p < 0.20 (signal expected)."""

    def test_scenario_3_quantitative_p_in_range(self):
        """Scenario 3 (quantitative null): omnibus p in [0.05, 1.0]."""

    def test_scenario_4_unequal_categories(self):
        """Scenario 4 (unequal category sizes): valid omnibus p returned."""

    def test_scenario_5_single_variant_per_category(self):
        """Scenario 5 (minimum 1 variant per category): valid omnibus p returned."""

    def test_all_7_component_pvalues_valid(self):
        """All 7 component p-values (6 burden + 1 SKAT) are in (0, 1]."""

    def test_burden_labels_match_expected(self):
        """Component labels match expected ordering."""
```

**IMPORTANT NOTE:** The golden R reference values will be PLACEHOLDER values initially. The user will run `Rscript scripts/generate_coast_golden.R` offline to get the actual values, and then update the constants. The tests should be structured so they work with placeholders (self-consistency checks) and can later be tightened with real R values.

Add `coast` to pytest markers in `pyproject.toml` if not already present (it was added in Phase 23).

All tests: `@pytest.mark.unit` and `@pytest.mark.coast` markers. Ruff: 100 char line length.
  </action>
  <verify>
`pytest tests/unit/test_coast_python.py -x -v` passes.
`pytest tests/unit/test_coast_python_comparison.py -x -v` passes.
`ruff check tests/unit/test_coast_python.py tests/unit/test_coast_python_comparison.py` passes.
`pytest tests/unit/test_coast.py -x` still passes (no regression).
`pytest tests/unit/ -k "skat" -x` still passes (no regression).
`make test-fast` passes.
  </verify>
  <done>
1. R golden file script exists at scripts/generate_coast_golden.R covering 5 scenarios
2. test_coast_python.py has comprehensive unit tests for each COAST component and PurePythonCOASTTest lifecycle
3. test_coast_python_comparison.py has validation tests structured for R golden reference values
4. All existing tests pass (no regressions)
5. `make test-fast` passes
  </done>
</task>

</tasks>

<verification>
1. `pytest tests/unit/test_coast_python.py tests/unit/test_coast_python_comparison.py -x -v` all pass
2. `pytest tests/unit/test_coast.py -x` still passes (existing tests)
3. `pytest tests/unit/test_skat_python_comparison.py -x` still passes (SKAT not affected)
4. `ruff check tests/unit/test_coast_python.py tests/unit/test_coast_python_comparison.py scripts/generate_coast_golden.R` passes (R file excluded from ruff)
5. `make test-fast` passes
6. `make ci-check` passes
</verification>

<success_criteria>
- R script generates golden values for 5 COAST scenarios using AllelicSeries::COAST()
- Python unit tests verify each burden model, allelic SKAT, and Cauchy combination independently
- Comparison tests are structured for R golden reference values with tiered tolerance
- PurePythonCOASTTest lifecycle tests pass (check_deps, prepare, run, finalize)
- Engine registry swap test confirms --coast-backend python works
- All existing tests pass with zero regressions
- `make ci-check` passes
</success_criteria>

<output>
After completion, create `.planning/phases/24-pure-python-coast-backend/24-03-SUMMARY.md`
</output>
