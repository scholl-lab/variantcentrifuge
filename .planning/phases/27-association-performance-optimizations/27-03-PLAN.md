---
phase: 27-association-performance-optimizations
plan: 03
type: execute
wave: 2
depends_on: ["27-01", "27-02"]
files_modified:
  - variantcentrifuge/association/engine.py
  - tests/unit/test_parallel_association.py
autonomous: true

must_haves:
  truths:
    - "Association engine runs genes in parallel when association_workers > 1 and all tests are parallel_safe"
    - "Parallel execution produces identical results to sequential execution"
    - "R backend tests (parallel_safe=False) force sequential fallback with a warning"
    - "Null models are pre-fitted before parallel dispatch"
    - "BLAS thread oversubscription is prevented in worker processes"
  artifacts:
    - path: "variantcentrifuge/association/engine.py"
      provides: "ProcessPoolExecutor parallel gene loop and module-level worker function"
      contains: "_run_gene_worker"
    - path: "tests/unit/test_parallel_association.py"
      provides: "Tests for parallel execution correctness and fallback behavior"
      contains: "test_parallel_results_match_sequential"
  key_links:
    - from: "variantcentrifuge/association/engine.py"
      to: "concurrent.futures.ProcessPoolExecutor"
      via: "run_all() dispatches genes to workers"
      pattern: "ProcessPoolExecutor"
    - from: "variantcentrifuge/association/engine.py"
      to: "variantcentrifuge/association/base.py"
      via: "reads config.association_workers"
      pattern: "association_workers"
    - from: "variantcentrifuge/association/engine.py"
      to: "pickle"
      via: "pickles test instances with pre-fitted null models for workers"
      pattern: "pickle\\.dumps"
---

<objective>
Add ProcessPoolExecutor-based gene-level parallelization to AssociationEngine.run_all(),
enabling ~Nx wall-clock speedup for multi-gene panels when all registered tests are
parallel-safe.

Purpose: With GL quadrature already reducing per-gene SKAT-O from 379ms to 8ms (Plan 01),
parallelization provides the second major performance lever -- distributing gene-level work
across N worker processes for panels with hundreds or thousands of genes.

Output: Modified engine.py with parallel gene dispatch, plus unit tests verifying result
identity between parallel and sequential execution.
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/27-association-performance-optimizations/27-RESEARCH.md

@variantcentrifuge/association/engine.py
@variantcentrifuge/association/base.py
@variantcentrifuge/association/tests/skat_python.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: ProcessPoolExecutor parallel gene loop in engine.py</name>
  <files>variantcentrifuge/association/engine.py</files>
  <action>
  1. Add a module-level worker function BEFORE the `AssociationEngine` class definition
     (after the `_build_registry` function). This MUST be module-level for pickle
     compatibility with ProcessPoolExecutor:

     ```python
     def _run_gene_worker(
         args: tuple[str, dict, bytes, "AssociationConfig"],
     ) -> tuple[str, dict[str, "TestResult"]]:
         """Process a single gene in a subprocess worker.

         Called by ProcessPoolExecutor. Receives pre-pickled test instances
         (with null models already fitted) to avoid redundant null model fitting
         in each worker.

         Parameters
         ----------
         args : tuple
             (gene_name, gene_data_dict, pickled_tests_bytes, config)
         """
         gene, gene_data, pickled_tests, config = args
         import pickle
         tests: dict[str, AssociationTest] = pickle.loads(pickled_tests)
         results: dict[str, TestResult] = {}
         for test_name, test in tests.items():
             result = test.run(gene, gene_data, config)
             results[test_name] = result
         return gene, results
     ```

  2. Add a worker initializer function (also module-level) that sets BLAS thread counts:

     ```python
     def _worker_initializer() -> None:
         """Set BLAS thread counts to 1 in worker processes to prevent oversubscription."""
         import os
         os.environ["OPENBLAS_NUM_THREADS"] = "1"
         os.environ["MKL_NUM_THREADS"] = "1"
         os.environ["OMP_NUM_THREADS"] = "1"
     ```

  3. Modify `run_all()` to support parallel execution. The key changes are in the gene
     loop section (currently lines 314-321). Replace the sequential loop with:

     a. After `test.prepare(len(sorted_data))` calls (line 312), determine parallelism:
        ```python
        n_workers = self._config.association_workers
        all_parallel_safe = all(
            getattr(test, "parallel_safe", False) for test in self._tests.values()
        )
        use_parallel = n_workers != 1 and all_parallel_safe and len(sorted_data) > 1

        if n_workers != 1 and not all_parallel_safe:
            logger.warning(
                "association_workers=%d requested but not all tests are parallel_safe "
                "(falling back to sequential). Non-parallel tests: %s",
                n_workers,
                [n for n, t in self._tests.items() if not getattr(t, "parallel_safe", False)],
            )
        ```

     b. If `use_parallel`:
        - Run first gene sequentially through all tests (triggers lazy null model fitting
          in SKAT/COAST tests):
          ```python
          first_gene = sorted_data[0]
          first_gene_name = first_gene.get("GENE", "")
          for test_name, test in self._tests.items():
              result = test.run(first_gene_name, first_gene, self._config)
              results_by_test[test_name][first_gene_name] = result
          ```
        - Pickle the test instances (now with null models):
          ```python
          import pickle
          pickled_tests = pickle.dumps(self._tests)
          ```
        - Dispatch remaining genes via ProcessPoolExecutor:
          ```python
          import concurrent.futures
          import os

          remaining = sorted_data[1:]
          actual_workers = os.cpu_count() if n_workers == -1 else n_workers
          # Minimum gene threshold: don't parallelize tiny panels
          if len(remaining) < actual_workers * 2:
              actual_workers = max(1, len(remaining) // 2)

          logger.info(
              f"Parallel association: {actual_workers} workers for "
              f"{len(remaining)} remaining genes"
          )

          args_list = [
              (gd.get("GENE", ""), gd, pickled_tests, self._config)
              for gd in remaining
          ]
          with concurrent.futures.ProcessPoolExecutor(
              max_workers=actual_workers,
              initializer=_worker_initializer,
          ) as executor:
              for gene, gene_results in executor.map(_run_gene_worker, args_list):
                  for test_name, result in gene_results.items():
                      results_by_test[test_name][gene] = result
          ```

     c. If NOT `use_parallel`: keep the existing sequential loop unchanged:
        ```python
        for gene_data in sorted_data:
            gene = gene_data.get("GENE", "")
            for test_name, test in self._tests.items():
                result = test.run(gene, gene_data, self._config)
                results_by_test[test_name][gene] = result
        ```

  4. The `finalize()` calls, ACAT-O computation, FDR correction, and DataFrame building
     remain UNCHANGED after the gene loop.

  5. Add `import os` at the top of the file if not already present.

  IMPORTANT: Do NOT change the ACAT-O post-loop logic, FDR correction, or DataFrame
  building. Only the gene loop section changes. The parallel path must produce the same
  `results_by_test` dict structure as the sequential path so all downstream code works
  identically.
  </action>
  <verify>
  Run existing engine tests: `pytest tests/unit/test_engine_skat_integration.py -v -x`
  Run: `pytest tests/unit/test_skat_python_backend.py -v -x`
  All existing tests pass (they use default workers=1, so the sequential path is exercised).
  Run: `make lint`
  </verify>
  <done>
  `engine.py` has `_run_gene_worker` and `_worker_initializer` at module level.
  `run_all()` uses ProcessPoolExecutor when workers > 1 and all tests are parallel_safe.
  First gene runs sequentially to pre-fit null models. Sequential fallback works when
  any test has parallel_safe=False. All existing tests pass.
  </done>
</task>

<task type="auto">
  <name>Task 2: Parallel execution tests</name>
  <files>tests/unit/test_parallel_association.py</files>
  <action>
  Create `tests/unit/test_parallel_association.py` with these tests:

  1. `test_parallel_results_match_sequential`: Generate synthetic gene burden data for
     5 genes (use FisherExactTest which is fast and has parallel_safe=True). Run
     `engine.run_all()` with `association_workers=1` (sequential) and `association_workers=2`
     (parallel). Assert the resulting DataFrames are identical (use `pd.testing.assert_frame_equal`).
     Use `AssociationConfig(association_workers=N)` and `AssociationEngine.from_names(["fisher"], config)`.

     Gene data generation pattern (from existing tests):
     ```python
     genes = []
     for i in range(5):
         genes.append({
             "GENE": f"GENE{i}",
             "proband_count": 100,
             "control_count": 100,
             "proband_carrier_count": 10 + i,
             "control_carrier_count": 5 + i,
             "proband_allele_count": 12 + i,
             "control_allele_count": 6 + i,
             "n_qualifying_variants": 3 + i,
         })
     ```

  2. `test_parallel_fallback_on_unsafe_test`: Create a mock test class with
     `parallel_safe = False`. Configure engine with `association_workers=2` and this
     mock test. Verify that `run_all()` falls back to sequential execution (check that
     the logger emits a warning containing "falling back to sequential"). Use
     `unittest.mock.patch` on the logger.

  3. `test_parallel_single_gene_stays_sequential`: With `association_workers=2` but only
     1 gene in the data, verify the parallel path is NOT taken (since `len(sorted_data) > 1`
     would be False). This just needs to complete without error and produce correct output.

  4. `test_worker_initializer_sets_env`: Call `_worker_initializer()` and assert
     `os.environ["OPENBLAS_NUM_THREADS"] == "1"` and `os.environ["MKL_NUM_THREADS"] == "1"`.
     Clean up env vars in teardown.

  Mark all tests with `@pytest.mark.unit`. The parallel test (test 1) may need a slightly
  longer timeout since it spawns subprocesses.
  </action>
  <verify>
  Run: `pytest tests/unit/test_parallel_association.py -v -x --timeout=60`
  All 4 tests pass.
  Run: `pytest -m unit --timeout=120 -x -q` -- full unit suite passes.
  Run: `make ci-check` -- all CI checks pass.
  </verify>
  <done>
  Parallel execution tests confirm: results match sequential, unsafe tests force fallback,
  single-gene stays sequential, worker initializer sets BLAS env vars. Full CI suite passes.
  </done>
</task>

</tasks>

<verification>
1. `pytest tests/unit/test_parallel_association.py -v` -- all parallel tests pass
2. `pytest tests/unit/test_engine_skat_integration.py -v` -- existing integration tests pass
3. `pytest -m unit --timeout=120` -- full unit suite passes
4. `make ci-check` -- all CI checks pass (lint, format, typecheck, tests)
</verification>

<success_criteria>
1. `run_all()` with `association_workers=2` and Fisher test produces identical DataFrame to `association_workers=1`
2. Non-parallel-safe tests force sequential fallback with warning
3. Worker processes set OPENBLAS_NUM_THREADS=1 to prevent BLAS oversubscription
4. Null models are pre-fitted by running first gene sequentially before parallel dispatch
5. All existing tests pass without regression
</success_criteria>

<output>
After completion, create `.planning/phases/27-association-performance-optimizations/27-03-SUMMARY.md`
</output>
