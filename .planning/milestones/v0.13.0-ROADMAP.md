# Milestone v0.13.0: Performance Optimization

**Status:** SHIPPED 2026-02-16
**Phases:** 6-12
**Total Plans:** 26

## Overview

3-4x full pipeline speedup on large cohorts through benchmarking infrastructure and systematic optimization of DataFrame operations, inheritance analysis, and output generation. Achieved >10x improvement (10+ hours to under 1 hour).

## Phases

### Phase 6: Benchmark Framework

**Goal**: Performance benchmarking infrastructure exists with synthetic data and regression detection
**Depends on**: Nothing (first phase of milestone)
**Plans**: 4 plans

Plans:
- [x] 06-01: Foundation: pytest-benchmark dep, synthetic data generators, memory helpers, conftest fixtures
- [x] 06-02: Component benchmarks: inheritance, comp_het, genotype replacement, gene burden, scoring, DataFrame I/O
- [x] 06-03: Ratio assertions (vectorized vs sequential) and memory budget enforcement via tracemalloc
- [x] 06-04: Macro pipeline benchmarks, result diff helper, end-to-end suite verification

**Details:**
- 60 benchmark tests across 8 files
- Synthetic data generators at 100, 1K, 10K, 50K variants
- Ratio assertions compare vectorized vs sequential within same run
- 20%+ regression canary assertions
- Memory budget enforcement via tracemalloc

### Phase 7: Quick Wins - Tier 1

**Goal**: Immediate 30-40% speedup through zero-risk standard optimizations
**Depends on**: Phase 6 (benchmarks prove improvement)
**Plans**: 3 plans

Plans:
- [x] 07-01: Dead code removal (gene_burden.py GT parsing loop) + temp file leak fixes
- [x] 07-02: observed=True on all 17 groupby sites + gc.collect() + pre-commit hook
- [x] 07-03: Full benchmark suite run and comparison against baseline

**Details:**
- Removed 30-line dead GT parsing loop from gene_burden.py
- Fixed 3 temp file leaks (gene_bed.py, filters.py)
- Added observed=True to all 17 groupby call sites
- gc.collect() after every pipeline stage execution
- Achieved 48-98% gene burden speedup (exceeded 30-40% target)

### Phase 8: DataFrame Optimization

**Goal**: 50-70% memory reduction and 2-3x I/O speedup through optimal DataFrame loading
**Depends on**: Phase 7 (observed=True must exist before categorical dtypes)
**Plans**: 4 plans

Plans:
- [x] 08-01: DataFrame optimizer utility (PyArrow engine, categorical auto-detection, column sanitization)
- [x] 08-02: Replace iterrows with itertuples across 14 hot-path sites in 9 files
- [x] 08-03: DataFrame pass-through for Excel stage + column name restoration
- [x] 08-04: Benchmark verification: memory reduction, I/O speedup, iteration speedup

**Details:**
- PyArrow engine for CSV reads (3.0x I/O speedup at scale)
- Categorical dtypes for low-cardinality columns (82-84% memory reduction)
- itertuples migration (30.9x iteration speedup)
- Column sanitization: GEN[0].GT → GEN_0__GT (restored at output time)
- In-memory DataFrame pass-through to Excel stage

### Phase 9: Inheritance Analysis Optimization

**Goal**: 10-100x speedup on inheritance analysis through full NumPy vectorization
**Depends on**: Phase 8 (categorical dtypes enable vectorization, itertuples established)
**Plans**: 5 plans

Plans:
- [x] 09-01: Golden file validation infrastructure (10 synthetic scenarios, Parquet format)
- [x] 09-02: Vectorize Pass 1: NumPy boolean mask pattern deduction
- [x] 09-03: Vectorize Pass 2 (comp het application) + optimize Pass 3 (bulk assignment)
- [x] 09-04: Consolidate comp het (remove comp_het.py) + update parallel_analyzer.py
- [x] 09-05: Benchmark verification: measure vectorization speedup

**Details:**
- vectorized_deducer.py: 802-line NumPy boolean mask implementation
- Genotype matrix encoding (n_variants x n_samples int8) built once
- Pass 1: 3.9-7.1x speedup; Full analysis: 40-47% improvement
- Original comp_het.py removed (vectorized is sole implementation)
- 14 golden file tests ensure clinical equivalence

### Phase 10: Output Optimization

**Goal**: 2-5x faster Excel generation and eliminate redundant GT parsing
**Depends on**: Phase 8 (DataFrame in-memory pass-through must exist)
**Plans**: 3 plans

Plans:
- [x] 10-01: Two-pass Excel (xlsxwriter bulk + openpyxl finalization)
- [x] 10-02: GT column pre-parsing at DataFrame load time + cache cleanup
- [x] 10-03: Excel generation benchmarks + fidelity tests

**Details:**
- xlsxwriter for fast bulk write + openpyxl for hyperlinks, freeze panes, auto-filters
- Module-level GT_PATTERN regex constant (eliminates per-row re.compile)
- GT column parsed once into _GT_PARSED cache at load time
- 5 fidelity tests + 10 xlsxwriter tests verify output equivalence

### Phase 11: Pipeline I/O Elimination

**Goal**: Eliminate genotype replacement stage (7 hrs) and replace SnpSift extractFields with bcftools query (2.7 hrs)
**Depends on**: Phase 9 (inheritance analysis must be decoupled from replaced GT format)
**Plans**: 3 plans

Plans:
- [x] 11-01: Replace SnpSift extractFields with bcftools query + Python ANN parsing
- [x] 11-02: Skip GenotypeReplacementStage, defer GT reconstruction to output time
- [x] 11-03: Validation tests (GT reconstruction, phenotype equivalence, pipeline data flow)

**Details:**
- bcftools query 19.4x faster than SnpSift extractFields
- Per-sample GT columns from bcftools eliminate genotype replacement need
- GT reconstruction deferred to output time (<1 min vs 7 hrs)
- 25 comprehensive tests proving equivalence
- SnpSift filter retained (bcftools cannot replicate na/has/ANN[ANY] operators)

### Phase 12: Parallelization & Chunking

**Goal**: Pipeline-wide resource management, auto-tuned parallelism, and memory-efficient processing
**Depends on**: Phase 11 (pipeline I/O elimination must be complete first)
**Plans**: 4 plans

Plans:
- [x] 12-01: Pipeline-wide ResourceManager (memory/CPU detection, auto-chunking, auto-workers)
- [x] 12-02: Migrate inheritance to ResourceManager, gene sorting, delete InheritanceMemoryManager
- [x] 12-03: Per-stage memory reporting in pipeline runner (INFO-level RSS tracking)
- [x] 12-04: Parallelism benchmarks + full verification sweep

**Details:**
- ResourceManager: CLI > SLURM > PBS > cgroup > psutil memory detection
- Gene sorting (largest-first) for load-balanced parallel processing
- Per-stage RSS memory tracking with INFO-level reporting
- InheritanceMemoryManager fully removed (zero references)
- Dead CLI flags removed (--chunks, --vectorized-chunk-size, etc.)

---

## Milestone Summary

**Key Decisions:**

- Benchmarks before optimization: Can't prove improvement without baseline measurements
- Local benchmarks only (no CI workflow): Get benchmarks working first, CI integration deferred
- Column sanitization permanent at load time: GEN[0].GT → GEN_0__GT, restored at output
- Conservative compound het: No pairing when phase ambiguous (avoids false positives)
- bcftools query over +split-vep: query 19x faster; +split-vep drops variants without ANN
- GenotypeReplacementStage eliminated via no-op: GT reconstruction deferred to output time
- psutil RSS for memory reporting: Tracks all memory including C extensions

**Issues Resolved:**

- Pipeline reduced from 10+ hours to under 1 hour on large cohorts
- Gene burden dead code loop eliminated (30 lines, 48-98% speedup)
- Temp file leaks fixed (gene_bed.py, filters.py)
- All groupby calls protected with observed=True (prevents 3500x categorical slowdown)
- InheritanceMemoryManager replaced with pipeline-wide ResourceManager
- comp_het.py consolidated to single vectorized implementation

**Issues Deferred:**

- CI benchmark workflow (github-action-benchmark) — deferred to future milestone
- Classic pipeline deprecation (DEPR-01) — tracked in backlog
- ~100 lines unreachable dead code in GenotypeReplacementStage

**Technical Debt Incurred:**

- Aspirational 10-100x Pass 1 target not met (achieved 4-8x) — Amdahl's Law, not a real gap
- ~100 lines unreachable code in processing_stages.py after GenotypeReplacementStage early return

---

_For current project status, see .planning/ROADMAP.md_
