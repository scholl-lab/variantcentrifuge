# Milestone v0.17.0: Tech Debt Cleanup & Compound Het Parallelization

**Status:** SHIPPED 2026-02-27
**Phases:** 38-39
**Total Plans:** 5

## Overview

Eliminate dead code, fix stale documentation, clean up minor tech debt, and parallelize the GIL-bound compound het pass for measurable speedup on multi-core systems.

**Scope:** 16 requirements across 4 categories (Performance, Dead Code, Documentation, Cleanup). The cleanup work (Phase 38) was entirely low-risk and behaviorally inert. The compound het parallelization (Phase 39) was the single complex item, attempted and reverted after real-data regression.

## Phases

### Phase 38: Codebase Cleanup

**Goal:** The codebase contains no dead code, stale documentation, or unresolved minor tech debt — any developer reading the source sees accurate, current state.
**Depends on:** None
**Plans:** 3 plans

Plans:
- [x] 38-01-PLAN.md — Dead code removal (DEAD-01 through DEAD-05, CLEAN-04, CLEAN-05)
- [x] 38-02-PLAN.md — Documentation and comment fixes (DOCS-01, DOCS-02, DOCS-03, CLEAN-01, CLEAN-02, CLEAN-07)
- [x] 38-03-PLAN.md — Code cleanup (CLEAN-03, CLEAN-06)

**Details:**

- Deleted `stage_info.py` (509 lines, never imported)
- Removed `--coast-backend r` CLI choice (no implementation exists)
- Removed 9 dead functions from `prioritizer.py` (5) and `analyzer.py` (4)
- Renamed `create_inheritance_details` → `_create_inheritance_details` (private helper)
- Fixed `--gzip-intermediates` flag confusion (only `--no-gzip-intermediates` remains)
- Corrected stale docs: `faq.md` removed flags, `association_testing.md` column name, `changelog.md` classic pipeline ref
- Updated stale docstrings/comments in 6 files
- Added 6 missing `__all__` exports to `stages/__init__.py`
- Removed dead test methods and resolved stale TODOs
- Success criteria: 5/5 verified, `make ci-check` passes (2066 tests, 0 failures)

---

### Phase 39: Compound Het Parallelization

**Goal:** Users running large cohorts on multi-core machines get measurably faster compound het analysis — the GIL-bound Pass 2 loop replaced by true parallelism.
**Depends on:** Phase 38 (clean codebase as starting point, no functional dependency)
**Plans:** 2 plans

Plans:
- [x] 39-01-PLAN.md — Synthetic benchmark script and baseline capture
- [x] 39-02-PLAN.md — Core optimization (attempted, reverted after real-data regression)

**Details:**

- Created standalone benchmark script (`standalone_bench_comp_het_parallel.py`)
- Baseline confirmed GIL contention: parallel 0.21x-0.92x vs sequential (synthetic data)
- Implemented numpy-only worker (`_process_gene_group_arrays`), pedigree arrays, pre-dispatch dedup
- Synthetic benchmarks showed 1.06x-1.66x speedup with 2+ workers
- Real-data benchmark (502 genes, 5125 samples, GCKD) showed 2x regression
- Full revert applied; net surviving change: `_get_batch_size()` env var override only
- Benchmark script retained for future optimization attempts

**Outcome:** Optimization reverted. PERF-01 and PERF-02 not achieved.

---

## Milestone Summary

**Key Decisions:**

- `create_inheritance_details` renamed to `_create_inheritance_details` (internal helper, underscore prefix signals private)
- `PATTERN_CATEGORIES` constant removed with its only consumer (`get_pattern_category`)
- `stages/__init__.py` `__all__` sorted alphabetically (ruff RUF022 requires isort-style sort)
- TODO intelligent batching replaced with deferred-work NOTE (current fixed-size batching sufficient)
- Compound het benchmark measures total wall-time (all 3 passes), not isolated Pass 2
- Pre-dispatch dedup in main thread eliminates per-worker drop_duplicates() call
- Pedigree arrays (int32/int8) indexed by sample position replace dict.get() in workers

**Issues Resolved:**

- 509-line dead module (`stage_info.py`) removed
- 11 dead inheritance functions removed
- Stale CLI flag references corrected in docs
- Missing `__all__` exports added
- Stale TODOs and comments cleaned up

**Issues Deferred:**

- `test_pipeline_with_mocked_tools.py` mocks wrong module namespace (pre-existing, not in scope)

**Technical Debt Incurred:**

- None new. Pre-existing integration test mock issue carried forward.

**Post-Mortem (Phase 39):**

The numpy-only `_process_gene_group_arrays` worker was 2x slower than the original DataFrame-based `_process_gene_group` on real data (502 genes, 5125 samples). Root causes: 2D fancy indexing creates cache-unfriendly copies, per-sample Python loops negate vectorization gains, memory bus saturation under 8 ThreadPoolExecutor workers. Lesson: always benchmark with production-scale data.

---

_For current project status, see .planning/ROADMAP.md_
