name: Documentation Build with SEO

on:
  push:
    branches: [main]
    paths:
      - "docs/**"
      - "variantcentrifuge/**"
      - ".github/workflows/docs-seo.yml"
  pull_request:
    branches: [main]
    paths:
      - "docs/**"
      - "variantcentrifuge/**"
      - ".github/workflows/docs-seo.yml"
  workflow_dispatch:

permissions:
  contents: read
  pages: write
  id-token: write

concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  build:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full history for git timestamps

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.10"
          cache: "pip"

      - name: Install documentation dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r docs/requirements.txt
          pip install -e .

      - name: Validate robots.txt
        run: |
          if [ -f "docs/source/_static/robots.txt" ]; then
            echo "✓ robots.txt found"
            # Basic validation
            grep -q "User-agent:" docs/source/_static/robots.txt || exit 1
            grep -q "Sitemap:" docs/source/_static/robots.txt || exit 1
          else
            echo "✗ robots.txt not found"
            exit 1
          fi

      - name: Build documentation with SEO
        run: |
          cd docs
          make clean
          make html
          echo "Documentation built successfully"

      - name: Validate SEO output
        run: |
          # Check if sitemap was generated
          if [ -f "docs/build/html/sitemap.xml" ]; then
            echo "✓ sitemap.xml generated"
            # Validate XML structure
            python -c "import xml.etree.ElementTree as ET; ET.parse('docs/build/html/sitemap.xml')"
          else
            echo "✗ sitemap.xml not found"
            exit 1
          fi

          # Check if robots.txt was copied
          if [ -f "docs/build/html/robots.txt" ]; then
            echo "✓ robots.txt copied to output"
          else
            echo "✗ robots.txt not in output"
            exit 1
          fi

      - name: Check for structured data
        run: |
          # Check if index.html contains JSON-LD
          if grep -q 'application/ld+json' docs/build/html/index.html; then
            echo "✓ JSON-LD structured data found"
            # Extract and validate JSON-LD
            python3 << 'EOF'
import re
import json
with open('docs/build/html/index.html', 'r') as f:
    content = f.read()
    matches = re.findall(r'<script type="application/ld\+json">(.*?)</script>', content, re.DOTALL)
    for match in matches:
        try:
            json.loads(match)
            print('✓ Valid JSON-LD found')
        except:
            print('✗ Invalid JSON-LD: ' + match[:100] + '...')
            exit(1)
EOF
          else
            echo "✗ No structured data found in index.html"
            exit 1
          fi

      - name: Validate meta tags
        run: |
          # Check for essential meta tags in index.html
          python -c "
          import re
          with open('docs/build/html/index.html', 'r') as f:
              content = f.read()
          
          # Check for meta description
          if re.search(r'<meta name=\"description\"', content):
              print('✓ Meta description found')
          else:
              print('✗ Meta description missing')
              exit(1)
          
          # Check for OpenGraph tags
          if re.search(r'<meta property=\"og:title\"', content):
              print('✓ OpenGraph tags found')
          else:
              print('✗ OpenGraph tags missing')
              exit(1)
          
          # Check for canonical URL
          if re.search(r'<link rel=\"canonical\"', content):
              print('✓ Canonical URL found')
          else:
              print('✗ Canonical URL missing')
              exit(1)
          "

      - name: Generate SEO report
        if: always()
        run: |
          echo "## SEO Report" > seo-report.md
          echo "Generated at: $(date)" >> seo-report.md
          echo "" >> seo-report.md

          # Count pages in sitemap
          if [ -f "docs/build/html/sitemap.xml" ]; then
            PAGE_COUNT=$(grep -c "<url>" docs/build/html/sitemap.xml || echo "0")
            echo "- Total pages indexed: $PAGE_COUNT" >> seo-report.md
          fi

          # Check file sizes
          echo "" >> seo-report.md
          echo "### File Sizes" >> seo-report.md
          find docs/build/html -name "*.html" -type f -exec ls -lh {} \; | head -10 >> seo-report.md

          echo "" >> seo-report.md
          echo "### Structured Data Summary" >> seo-report.md
          grep -h "@type" docs/build/html/*.html | sort | uniq -c >> seo-report.md || true

      - name: Upload SEO report
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: seo-report
          path: seo-report.md

      - name: Setup Pages
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        uses: actions/configure-pages@v4

      - name: Upload artifact
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        uses: actions/upload-pages-artifact@v3
        with:
          path: docs/build/html

  deploy:
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: build
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

      - name: Submit sitemap to Google
        if: success()
        run: |
          # Submit sitemap to Google Search Console
          curl -s "https://www.google.com/ping?sitemap=https://scholl-lab.github.io/variantcentrifuge/sitemap.xml" || true

          # Submit to Bing
          curl -s "https://www.bing.com/ping?sitemap=https://scholl-lab.github.io/variantcentrifuge/sitemap.xml" || true
