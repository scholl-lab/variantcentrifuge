# File: variantcentrifuge/analyze_variants.py
# Location: variantcentrifuge/variantcentrifuge/analyze_variants.py

"""
Variant analysis module.

This module performs basic variant statistics and an optional gene burden analysis
using Fisher's exact test. It is designed to output statistics in a consistent,
two-column (metric, value) format to simplify parsing and appending to XLSX sheets.

Changes:
- Removed 'proband_count', 'proband_allele_count', 'control_count', 'control_allele_count'
  from required columns. These are now optional and default to zero if missing.
- Outputs basic and comprehensive statistics in a uniform (metric, value) TSV format.
- No extra lines or headers that break TSV parsing are added.
- Comprehensive stats are generated by pivoting gene-level summaries into metric-value pairs.
- Gene burden analysis remains optional and is only performed if requested.
"""

import io
import pandas as pd
from collections import Counter
import logging
from math import isnan

try:
    from scipy.stats import fisher_exact
except ImportError:
    fisher_exact = None

logger = logging.getLogger("variantcentrifuge")

def analyze_variants(lines, cfg):
    """
    Analyze variants, potentially performing gene burden analysis and writing statistics.

    Parameters
    ----------
    lines : iterator of str
        Iterator of TSV lines containing variant data.
    cfg : dict
        Configuration dictionary which may include:
        - perform_gene_burden (bool): Perform gene burden analysis if True.
        - stats_output_file (str): Path to write statistics in metric-value format.
        - no_stats (bool): If True, skip the comprehensive statistics computation.

    Returns
    -------
    iterator of str
        If perform_gene_burden is True, yields gene burden analysis results as TSV lines.
        Otherwise, yields the original lines unchanged.
    """
    perform_gene_burden = cfg.get("perform_gene_burden", False)
    stats_output_file = cfg.get("stats_output_file")
    no_stats = cfg.get("no_stats", False)

    logger.debug(f"analyze_variants: perform_gene_burden={perform_gene_burden}, "
                 f"stats_output_file={stats_output_file}, no_stats={no_stats}")

    # Read all input lines into a DataFrame
    text_data = "".join(line for line in lines)
    if not text_data.strip():
        # No data provided
        logger.debug("analyze_variants: No input data provided.")
        return

    # Parse the input TSV into a DataFrame
    df = pd.read_csv(io.StringIO(text_data), sep="\t", dtype=str)
    logger.debug(f"analyze_variants: Loaded {len(df)} variants.")

    # Convert known numeric columns if they exist
    numeric_cols = ["proband_count", "proband_allele_count", "control_count", "control_allele_count"]
    for col in numeric_cols:
        if col in df.columns:
            df[col] = pd.to_numeric(df[col], errors="coerce").fillna(0)

    # Required columns now only include the basic variant descriptor columns and GT
    required_columns = ["CHROM", "POS", "REF", "ALT", "GENE", "GT"]
    missing_columns = [c for c in required_columns if c not in df.columns]
    if missing_columns:
        logger.error(f"Missing required columns: {', '.join(missing_columns)}. No stats will be computed.")
        # Return original lines unchanged since we can't compute stats
        for line in text_data.strip().split("\n"):
            yield line
        return

    # Compute basic statistics
    num_variants = len(df)

    # Extract sample names from GT fields
    all_samples = set()
    for val in df["GT"]:
        if isinstance(val, str) and val.strip():
            for s in val.split(";"):
                s = s.strip()
                if s:
                    idx = s.find("(")
                    if idx != -1:
                        s = s[:idx]
                    all_samples.add(s)
    num_samples = len(all_samples)

    # Count number of unique genes
    num_genes = df["GENE"].nunique()

    # Count Het/Hom occurrences from GT fields
    het_counts = 0
    hom_counts = 0
    for val in df["GT"]:
        if isinstance(val, str) and val.strip():
            for g in val.split(";"):
                g = g.strip()
                genotype = extract_genotype(g)
                if genotype in ["0/1", "1/0"]:
                    het_counts += 1
                elif genotype == "1/1":
                    hom_counts += 1

    # Variant types (EFFECT)
    variant_types = None
    if "EFFECT" in df.columns:
        variant_types = df["EFFECT"].value_counts().reset_index()
        variant_types.columns = ["EFFECT", "count"]

    # Impact types (IMPACT)
    impact_types = None
    if "IMPACT" in df.columns:
        impact_types = df["IMPACT"].value_counts().reset_index()
        impact_types.columns = ["IMPACT", "count"]

    # Log some basic info
    logger.info(f"Number of variants: {num_variants}")
    logger.info(f"Number of samples: {num_samples}")
    logger.info(f"Number of genes: {num_genes}")
    logger.info(f"Het counts: {het_counts}")
    logger.info(f"Hom counts: {hom_counts}")

    if variant_types is not None:
        logger.info(f"Variant types:\n{variant_types}")
    else:
        logger.info("No EFFECT column present, skipping variant types.")

    if impact_types is not None:
        logger.info(f"Impact types:\n{impact_types}")
    else:
        logger.info("No IMPACT column present, skipping impact types.")

    # Prepare basic stats in metric-value format
    basic_stats = []
    basic_stats.append(["Number of variants", str(num_variants)])
    basic_stats.append(["Number of samples", str(num_samples)])
    basic_stats.append(["Number of genes", str(num_genes)])
    basic_stats.append(["Het counts", str(het_counts)])
    basic_stats.append(["Hom counts", str(hom_counts)])

    # Add variant types if available
    if variant_types is not None:
        for _, row in variant_types.iterrows():
            basic_stats.append([f"Variant_type_{row['EFFECT']}", str(row['count'])])

    # Add impact types if available
    if impact_types is not None:
        for _, row in impact_types.iterrows():
            basic_stats.append([f"Impact_type_{row['IMPACT']}", str(row['count'])])

    basic_stats_df = pd.DataFrame(basic_stats, columns=["metric", "value"])

    # Write basic stats if stats_output_file is provided
    if stats_output_file:
        logger.debug("Writing basic stats to stats_output_file in metric-value format.")
        basic_stats_df.to_csv(stats_output_file, sep="\t", index=False, header=True, mode="w")

    # Compute comprehensive stats if not disabled
    if not no_stats:
        logger.debug("Computing comprehensive stats...")
        comprehensive_df = compute_gene_stats(df)
        impact_summary = compute_impact_summary(df)
        variant_type_summary = compute_variant_type_summary(df)

        # Merge them into one DataFrame
        combined_stats = merge_and_format_stats(comprehensive_df, impact_summary, variant_type_summary)

        # Convert combined_stats to metric-value form, using GENE and column names as metrics
        comp_stats_list = []
        for _, row in combined_stats.iterrows():
            gene = row["GENE"]
            for col in combined_stats.columns:
                if col == "GENE":
                    continue
                val = row[col]
                comp_stats_list.append([f"{gene}_{col}", str(val)])

        if comp_stats_list and stats_output_file:
            comp_stats_df = pd.DataFrame(comp_stats_list, columns=["metric", "value"])
            logger.debug("Appending comprehensive stats to stats_output_file in metric-value format.")
            comp_stats_df.to_csv(stats_output_file, sep="\t", index=False, header=False, mode="a")
    else:
        logger.debug("no_stats is True, skipping comprehensive stats.")

    # Perform gene burden analysis if requested
    if perform_gene_burden:
        logger.debug("Performing gene burden analysis.")
        if fisher_exact is None:
            logger.error("scipy not available for Fisher test, cannot perform gene burden.")
            for line in text_data.strip().split("\n"):
                yield line
            return

        grouped = df.groupby("GENE").apply(gene_burden_fisher)
        burden_text = grouped.to_csv(sep="\t", index=False)
        for line in burden_text.strip().split("\n"):
            yield line
    else:
        logger.debug("No gene burden analysis requested, returning original data.")
        for line in text_data.strip().split("\n"):
            yield line


def extract_genotype(sample_field):
    """
    Extract the genotype from a sample field like 'sample(0/1)' or 'sample'.
    If parentheses are present, they contain the genotype, e.g. 'sample(0/1)'.
    Otherwise, returns an empty string if no genotype is appended.
    """
    start_idx = sample_field.find("(")
    end_idx = sample_field.find(")")
    if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
        return sample_field[start_idx+1:end_idx]
    return ""


def gene_burden_fisher(subdf):
    """
    Perform gene burden calculation for a group of variants from one gene.

    Parameters
    ----------
    subdf : DataFrame
        Subset of the main DataFrame filtered to one gene.

    Returns
    -------
    DataFrame
        A single-row DataFrame with columns:
        GENE, proband_alleles, control_alleles, max_proband_count, max_control_count,
        proband_ref_alleles, control_ref_alleles, fisher_p_value
    """
    if "proband_allele_count" not in subdf.columns:
        subdf["proband_allele_count"] = 0
    if "control_allele_count" not in subdf.columns:
        subdf["control_allele_count"] = 0
    if "proband_count" not in subdf.columns:
        subdf["proband_count"] = 0
    if "control_count" not in subdf.columns:
        subdf["control_count"] = 0

    proband_alleles = subdf["proband_allele_count"].sum()
    control_alleles = subdf["control_allele_count"].sum()
    max_proband_count = subdf["proband_count"].max()
    max_control_count = subdf["control_count"].max()

    proband_ref_alleles = (max_proband_count * 2 * len(subdf)) - proband_alleles
    control_ref_alleles = (max_control_count * 2 * len(subdf)) - control_alleles

    table = [[proband_alleles, control_alleles],
             [proband_ref_alleles, control_ref_alleles]]

    oddsratio, p_value = fisher_exact(table)

    return pd.DataFrame([{
        "GENE": subdf["GENE"].iloc[0],
        "proband_alleles": proband_alleles,
        "control_alleles": control_alleles,
        "max_proband_count": max_proband_count,
        "max_control_count": max_control_count,
        "proband_ref_alleles": proband_ref_alleles,
        "control_ref_alleles": control_ref_alleles,
        "fisher_p_value": p_value
    }])


def compute_gene_stats(df: pd.DataFrame) -> pd.DataFrame:
    """
    Compute per-gene aggregated statistics, including variant and allele counts.
    If proband/control columns are missing, they are set to zero before aggregation.

    Parameters
    ----------
    df : DataFrame
        The main DataFrame with variant information.

    Returns
    -------
    DataFrame
        Per-gene aggregated statistics with columns:
        GENE, proband_count, control_count, proband_allele_count, control_allele_count
    """
    for col in ["proband_count", "control_count", "proband_allele_count", "control_allele_count"]:
        if col not in df.columns:
            df[col] = 0

    grouped = df.groupby("GENE").agg({
        "proband_count": "sum",
        "control_count": "sum",
        "proband_allele_count": "sum",
        "control_allele_count": "sum"
    }).reset_index()
    return grouped


def compute_impact_summary(df: pd.DataFrame) -> pd.DataFrame:
    """
    Generate per-gene impact summaries (HIGH, MODERATE, etc.) if IMPACT column exists.

    Parameters
    ----------
    df : DataFrame

    Returns
    -------
    DataFrame
        Pivoted table with IMPACT categories as columns and counts as values.
        Returns an empty DataFrame if IMPACT or GENE are missing.
    """
    if "GENE" not in df.columns or "IMPACT" not in df.columns:
        return pd.DataFrame()
    impact_counts = df.groupby(["GENE", "IMPACT"]).size().reset_index(name="count")
    pivot_impact = impact_counts.pivot(index="GENE", columns="IMPACT", values="count").fillna(0).reset_index()
    return pivot_impact


def compute_variant_type_summary(df: pd.DataFrame) -> pd.DataFrame:
    """
    Summarize per-gene EFFECT variant types if EFFECT column exists.

    Parameters
    ----------
    df : DataFrame

    Returns
    -------
    DataFrame
        Pivoted table with EFFECT categories as columns and counts as values.
        Returns an empty DataFrame if EFFECT or GENE are missing.
    """
    if "GENE" not in df.columns or "EFFECT" not in df.columns:
        return pd.DataFrame()
    type_counts = df.groupby(["GENE", "EFFECT"]).size().reset_index(name="count")
    pivot_types = type_counts.pivot(index="GENE", columns="EFFECT", values="count").fillna(0).reset_index()
    return pivot_types


def merge_and_format_stats(gene_stats: pd.DataFrame,
                           impact_summary: pd.DataFrame,
                           variant_type_summary: pd.DataFrame) -> pd.DataFrame:
    """
    Merge all computed statistics into a single cohesive DataFrame keyed by GENE.

    Parameters
    ----------
    gene_stats : DataFrame
        Per-gene basic stats.
    impact_summary : DataFrame
        Per-gene impact summary.
    variant_type_summary : DataFrame
        Per-gene variant type summary.

    Returns
    -------
    DataFrame
        A merged DataFrame with columns:
        GENE, proband_count, control_count, proband_allele_count, control_allele_count,
        plus any columns from impact_summary and variant_type_summary.
    """
    merged = gene_stats.copy()
    if not impact_summary.empty:
        merged = pd.merge(merged, impact_summary, on="GENE", how="left")
    if not variant_type_summary.empty:
        merged = pd.merge(merged, variant_type_summary, on="GENE", how="left")
    merged = merged.fillna(0)
    return merged
